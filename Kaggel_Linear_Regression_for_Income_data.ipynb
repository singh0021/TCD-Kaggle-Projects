{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.6"
    },
    "colab": {
      "name": "Kaggel Linear Regression for Income data.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/singh0021/TCD-Kaggle-Projects/blob/master/Kaggel_Linear_Regression_for_Income_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fruuijKPVrXs",
        "colab_type": "text"
      },
      "source": [
        "#I have built various model and tried various approaches. This notebook is specific to final solution. If anyone interested to know other approaches and visualization techniques. Please refer to other #notebook in same directory with name : Machine Learning Solution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t91fRIXhVrXu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMmZ2XiiVrXx",
        "colab_type": "text"
      },
      "source": [
        "# Lets load both training and Testing Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBVFfjeYVrXx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df =pd.read_csv(\"Data.csv\")\n",
        "train_df = train_df.drop(['Instance'], axis=1)\n",
        "test_df = pd.read_csv(\"tcdml2019-20incomepredictiontest(without labels).csv\")\n",
        "\n",
        "# We need to exclude negative incomes if we are normalizing Income variable using log, else we will comment this part as we are getting good RMSE score by using scaler approach\n",
        "#train_df = train_df[(train_df['Income in EUR'] > 0) ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5CljPtnWVS7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ga3WvZRUVrX0",
        "colab_type": "text"
      },
      "source": [
        "# Lets describe the training data and we see that there are negative incomes and few outliers. We can get rid of those rows"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "am9VkpWuVrX0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "outputId": "7766a192-6d4a-483d-9aa0-a6203e4e50bf"
      },
      "source": [
        "train_df.describe()\n",
        "#train_df = train_df[(train_df['Income in EUR'] > 0)]\n",
        "#train_df = train_df[train_df['Age'] < 110]\n",
        "#train_df = train_df[train_df['Body Height [cm]'] < 225]\n",
        "\n",
        "\n",
        "\n",
        "#Since accuracy improved a little bit after adding outliers, hence we kept outliers and let it run"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Year of Record</th>\n",
              "      <th>Age</th>\n",
              "      <th>Size of City</th>\n",
              "      <th>Wears Glasses</th>\n",
              "      <th>Body Height [cm]</th>\n",
              "      <th>Income in EUR</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>111552.000000</td>\n",
              "      <td>111499.000000</td>\n",
              "      <td>1.119930e+05</td>\n",
              "      <td>111993.000000</td>\n",
              "      <td>111993.000000</td>\n",
              "      <td>1.119930e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>1999.421274</td>\n",
              "      <td>37.345304</td>\n",
              "      <td>8.388538e+05</td>\n",
              "      <td>0.500531</td>\n",
              "      <td>175.220192</td>\n",
              "      <td>1.092138e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>11.576382</td>\n",
              "      <td>16.036694</td>\n",
              "      <td>2.196879e+06</td>\n",
              "      <td>0.500002</td>\n",
              "      <td>19.913889</td>\n",
              "      <td>1.498024e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1980.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>7.700000e+01</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>94.000000</td>\n",
              "      <td>-5.696906e+03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1989.000000</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>7.273400e+04</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>160.000000</td>\n",
              "      <td>3.077169e+04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1999.000000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>5.060920e+05</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>174.000000</td>\n",
              "      <td>5.733917e+04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>2009.000000</td>\n",
              "      <td>48.000000</td>\n",
              "      <td>1.184501e+06</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>190.000000</td>\n",
              "      <td>1.260936e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>2019.000000</td>\n",
              "      <td>115.000000</td>\n",
              "      <td>4.999251e+07</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>265.000000</td>\n",
              "      <td>5.285252e+06</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Year of Record            Age  ...  Body Height [cm]  Income in EUR\n",
              "count   111552.000000  111499.000000  ...     111993.000000   1.119930e+05\n",
              "mean      1999.421274      37.345304  ...        175.220192   1.092138e+05\n",
              "std         11.576382      16.036694  ...         19.913889   1.498024e+05\n",
              "min       1980.000000      14.000000  ...         94.000000  -5.696906e+03\n",
              "25%       1989.000000      24.000000  ...        160.000000   3.077169e+04\n",
              "50%       1999.000000      35.000000  ...        174.000000   5.733917e+04\n",
              "75%       2009.000000      48.000000  ...        190.000000   1.260936e+05\n",
              "max       2019.000000     115.000000  ...        265.000000   5.285252e+06\n",
              "\n",
              "[8 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmYOIwOYVrX2",
        "colab_type": "text"
      },
      "source": [
        "# Since there are 4-5 categorical variables and we have tested accucary of using few encoding such as one hot, label and target encoding. Target encoding gives me the best accurcay"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SfCUzKW5VrX3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def target_encoding(data, target, categories, smooth):\n",
        "    \n",
        "    train_target = data.copy()\n",
        "    code_map = dict()   \n",
        "    d_map = dict() \n",
        "    \n",
        "    for v in categories:\n",
        "        prior = data[target].mean()\n",
        "        n = data.groupby(v).size()\n",
        "        u = data.groupby(v)[target].mean()\n",
        "        mu_smoothed = (n * u + smooth * prior) / (n + smooth)\n",
        "        \n",
        "        train_target.loc[:, v] = train_target[v].map(mu_smoothed)        \n",
        "        code_map[v] = mu_smoothed\n",
        "        d_map[v] = prior        \n",
        "    return train_target, code_map, d_map"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4e6wUIETVrX5",
        "colab_type": "code",
        "outputId": "3fa83d4b-a57d-4937-9618-fdff2ced6ac6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(train_df['Profession'].unique())\n"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1341"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vzoiPpI5VrX9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "categories = ['Country', 'Profession', 'University Degree','Gender']\n",
        "train_smooth, target_m, d_m = target_encoding(train_df, 'Income in EUR', categories, 10)\n",
        "test_t = test_df.copy()\n",
        "for v in categories:\n",
        "    test_t.loc[:, v] = test_t[v].map(target_m[v])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5dfW35LVrX_",
        "colab_type": "text"
      },
      "source": [
        "# We ran this model multiple times to see which features are adding value to the model. Hence we have selected below feature which gives best accuracy so far."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3yv9DNfVrX_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final_trhot = train_smooth[['Age','Year of Record','Body Height [cm]', 'Country', 'University Degree','Profession'\n",
        "                                  ,'Size of City','Gender']]\n",
        "test_col = test_t[['Age','Year of Record','Body Height [cm]', 'Country', 'University Degree','Profession',\n",
        "                              'Size of City', 'Gender']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xh7eJLdgVrYD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# lets fill those missing values by taking means and since Income variable is skewed. We will take its log. I have commented log of Income variable as\n",
        "# we shall get error on negative incomes and we can get similar RMSE by taking scaler approach itself\n",
        "\n",
        "final_trhot = final_trhot.fillna(final_trhot.mean())\n",
        "test_col = test_col.fillna(test_col.mean())\n",
        "#y_t = np.log(train_df['Income in EUR'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_lDVYXaQmAf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initially i have used linear regression model which was giving me good accuracy. However, i have tried various models and got best RMSE in Random Forest Regressor and Hence i have commented\n",
        "# linear regression."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsbjKmdfVrYH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#from sklearn.preprocessing import StandardScaler\n",
        "# Xhot_tr, Xhot_ts, Yhot_tr, Yhot_ts = train_test_split(final_trhot, train_df['Income in EUR'], test_size=0.25, random_state = 7)\n",
        "\n",
        "#scaler = StandardScaler().fit(Xhot_tr)\n",
        "#rescaled_X_train = scaler.transform(Xhot_tr)\n",
        "\n",
        "#lm.fit(rescaled_X_train,Yhot_tr)\n",
        "\n",
        "#rescaled_X_ts = scaler.transform(Xhot_ts)\n",
        "#predictions = lm.predict(rescaled_X_ts)\n",
        "#print('The accuracy of the Linear Regression is',r2_score(Yhot_ts,predictions))\n",
        "#print ('MSE is: \\n', np.sqrt(mean_squared_error(Yhot_ts,predictions)))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mxq3sZ3lVrYI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "bfc36fff-f0d8-47ab-92bf-ed0970f8d46b"
      },
      "source": [
        "## Lets build RandomForest Regression model\n",
        "# estimators were chosen by running model multiple times by verifying accurcay and RMSE\n",
        "\n",
        "import numpy\n",
        "from sklearn import linear_model\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "Xhot_tr, Xhot_ts, Yhot_tr, Yhot_ts = train_test_split(final_trhot, train_df['Income in EUR'], test_size=0.25, random_state = 7)\n",
        "\n",
        "cls = RandomForestRegressor(n_estimators=250, criterion='mse', max_depth=30)\n",
        "\n",
        "\n",
        "scaler = StandardScaler().fit(Xhot_tr)\n",
        "rescaled_X_train = scaler.transform(Xhot_tr)\n",
        "\n",
        "rescaled_X_ts = scaler.transform(Xhot_ts)\n",
        "\n",
        "cls.fit(rescaled_X_train,Yhot_tr)\n",
        "y_pred = cls.predict(rescaled_X_ts)\n",
        "\n",
        "print('The accuracy of the Random Regression is',r2_score(Yhot_ts,y_pred))\n",
        "print ('RMSE is: \\n', np.sqrt(mean_squared_error(Yhot_ts,y_pred)))\n"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The accuracy of the Random Regression is 0.8242367173943914\n",
            "RMSE is: \n",
            " 61596.29906483522\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0JqpFhb5VrYK",
        "colab_type": "code",
        "outputId": "a3bfb556-d641-4fdb-b513-4fdd58b4dc85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "# Lets build Random forest regression model and check its accuracy\n",
        "# Below model is there just to showcase that if we normalize Y variable , our RMSE score decreases.\n",
        "\n",
        "import numpy\n",
        "from sklearn import linear_model\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "cls = RandomForestRegressor(n_estimators=250, criterion='mse', max_depth=30)\n",
        "\n",
        "Xhot_tr, Xhot_ts, Yhot_tr, Yhot_ts = train_test_split(final_trhot, y_t, test_size=0.25, random_state = 7)\n",
        "\n",
        "cls.fit(Xhot_tr, Yhot_tr)\n",
        "y_pred = cls.predict(Xhot_ts)\n",
        "\n",
        "print('The accuracy of the Linear Regression is',r2_score(Yhot_ts,y_pred))\n",
        "print ('RMSE is: \\n', (mean_squared_error(Yhot_ts,y_pred)))\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The accuracy of the Linear Regression is 0.9061189861964921\n",
            "RMSE is: \n",
            " 0.11295795555422353\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6v83fyvjVrYM",
        "colab_type": "text"
      },
      "source": [
        "# It is also important to note that RMSE score decreases if we take log of Income variable on validation data.Also, if we are not taking log of Income variable, we need to scale our data. Result are pretty much same on testing data only RMSE differs on local validation data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LwS2sh-vUidA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# After I got good accuracy on Random Forest Regression, I have tried other approaches such as XGB boost, GBM, CatBoost and ensemble one. Please do check conclusion of this notebook."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65XCNCt1Y93o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# There was error in column name due to spacing in headers, hence we fixed it\n",
        "\n",
        "import re\n",
        "\n",
        "regex = re.compile(r\"\\[|\\]|<\", re.IGNORECASE)\n",
        "\n",
        "final_trhot.columns = [regex.sub(\"_\", col) if any(x in str(col) for x in set(('[', ']', '<'))) else col for col in final_trhot.columns.values]\n",
        "#Xhot_ts.columns = [regex.sub(\"_\", col) if any(x in str(col) for x in set(('[', ']', '<'))) else col for col in Xhot_ts.columns.values]\n",
        "test_col.columns = [regex.sub(\"_\", col) if any(x in str(col) for x in set(('[', ']', '<'))) else col for col in test_col.columns.values]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkS_C_EVbbD0",
        "colab_type": "code",
        "outputId": "8ca37e88-01b9-4850-c462-705b0e39283b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        }
      },
      "source": [
        "# We tried implemented to improve accuracy more by using XGBoost. Estimators were chosen by running model multiple times by checking accurcay and RMSE\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "Xhot_tr, Xhot_ts, Yhot_tr, Yhot_ts = train_test_split(final_trhot, train_df['Income in EUR'], test_size=0.25, random_state = 7)\n",
        "\n",
        "scaler = StandardScaler().fit(Xhot_tr)\n",
        "rescaled_X_train = scaler.transform(Xhot_tr)\n",
        "\n",
        "rescaled_X_ts = scaler.transform(Xhot_ts)\n",
        "\n",
        "my_model = XGBRegressor(n_estimators=1000)\n",
        "xgb = my_model.fit(rescaled_X_train, Yhot_tr, early_stopping_rounds=5, \n",
        "             eval_set=[(rescaled_X_ts, Yhot_ts)], verbose=False)\n",
        "\n",
        "y_pred = xgb.predict(rescaled_X_ts)\n",
        "\n",
        "print('The accuracy of the XGB Regression is',r2_score(Yhot_ts,y_pred))\n",
        "print ('RMSE is: \\n', np.sqrt(mean_squared_error(Yhot_ts,y_pred)))\n"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
            "  if getattr(data, 'base', None) is not None and \\\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[06:49:06] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "The accuracy of the XGB Regression is 0.8388044065504278\n",
            "RMSE is: \n",
            " 58988.46894758571\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1I0CgCzrQHs",
        "colab_type": "code",
        "outputId": "66cc49d6-350e-4d2b-eb89-4d0752c46327",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(rescaled_X_ts)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "73230"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_HTu9C5OnBwa",
        "colab_type": "code",
        "outputId": "866b0456-b0e5-40db-b313-b6bc5db66d94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# Since XGBoost improved our RMSE on test data. I tried to use GBM too and it gave me a little boost. Estimators were decided by running model multiple times\n",
        "# and best RMSE estimator was chosen.\n",
        "\n",
        "\n",
        "from sklearn import ensemble\n",
        "\n",
        "clf = ensemble.GradientBoostingRegressor(n_estimators = 1200, max_depth = 7, min_samples_split = 2,\n",
        "          learning_rate = 0.1, loss = 'ls')\n",
        "\n",
        "clf.fit(rescaled_X_train, Yhot_tr)\n",
        "\n",
        "rescaled_X_ts = scaler.transform(Xhot_ts)\n",
        "predictions = clf.predict(rescaled_X_ts)\n",
        "\n",
        "print('The accuracy of the XGB Regression is',r2_score(Yhot_ts,predictions))\n",
        "print (np.sqrt(mean_squared_error(Yhot_ts, predictions)))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The accuracy of the XGB Regression is 0.8385447856030246\n",
            "59035.95312628629\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3PXU41SXlyY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "70dee111-d5ec-4ca9-9eca-369d7355a867"
      },
      "source": [
        "!pip install catboost"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting catboost\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/21/41/75b28629b9f2668548f431efe0236062aec12cd0a9a647313d7f2d1c9221/catboost-0.17.5-cp36-none-manylinux1_x86_64.whl (62.7MB)\n",
            "\u001b[K     |████████████████████████████████| 62.7MB 519kB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.6/dist-packages (from catboost) (0.24.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from catboost) (1.12.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from catboost) (1.3.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.6/dist-packages (from catboost) (4.1.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from catboost) (3.0.3)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from catboost) (1.16.5)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from catboost) (0.10.1)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.0->catboost) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.0->catboost) (2.5.3)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly->catboost) (1.3.3)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (2.4.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (0.10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib->catboost) (41.2.0)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-0.17.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2hV7VI8Y8fn",
        "colab_type": "code",
        "outputId": "15c1fbc3-5441-4c3b-f32b-728b3b5d8b28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Lets try on CatBoost also. Hyper parameters we have choosen by running model multiple times to see if RMSE improves\n",
        "\n",
        "from catboost import Pool, CatBoostRegressor\n",
        "\n",
        "cb = CatBoostRegressor(learning_rate=0.6, eval_metric='RMSE')\n",
        "cb.fit(rescaled_X_train, Yhot_tr)\n",
        "\n",
        "pred_cb = cb.predict(rescaled_X_ts)\n",
        "print('The accuracy of the CAT Regression is',r2_score(Yhot_ts,pred_cb))\n",
        "print (np.sqrt(mean_squared_error(Yhot_ts, pred_cb)))"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0:\tlearn: 97680.5366678\ttotal: 63.9ms\tremaining: 1m 3s\n",
            "1:\tlearn: 79282.2746772\ttotal: 79.5ms\tremaining: 39.7s\n",
            "2:\tlearn: 71694.3373939\ttotal: 93.8ms\tremaining: 31.2s\n",
            "3:\tlearn: 68244.8481124\ttotal: 108ms\tremaining: 26.8s\n",
            "4:\tlearn: 66387.8317059\ttotal: 122ms\tremaining: 24.2s\n",
            "5:\tlearn: 65380.5608201\ttotal: 135ms\tremaining: 22.3s\n",
            "6:\tlearn: 64708.7349565\ttotal: 150ms\tremaining: 21.3s\n",
            "7:\tlearn: 63976.4922164\ttotal: 166ms\tremaining: 20.6s\n",
            "8:\tlearn: 63552.8650642\ttotal: 180ms\tremaining: 19.8s\n",
            "9:\tlearn: 62901.8847681\ttotal: 194ms\tremaining: 19.2s\n",
            "10:\tlearn: 62193.2999011\ttotal: 208ms\tremaining: 18.7s\n",
            "11:\tlearn: 61910.4331420\ttotal: 221ms\tremaining: 18.2s\n",
            "12:\tlearn: 61407.1588230\ttotal: 236ms\tremaining: 17.9s\n",
            "13:\tlearn: 61009.3606543\ttotal: 249ms\tremaining: 17.6s\n",
            "14:\tlearn: 60774.4366280\ttotal: 262ms\tremaining: 17.2s\n",
            "15:\tlearn: 60546.0468672\ttotal: 283ms\tremaining: 17.4s\n",
            "16:\tlearn: 60401.8525980\ttotal: 298ms\tremaining: 17.2s\n",
            "17:\tlearn: 60012.2496447\ttotal: 312ms\tremaining: 17s\n",
            "18:\tlearn: 59715.3365827\ttotal: 325ms\tremaining: 16.8s\n",
            "19:\tlearn: 59542.0482207\ttotal: 338ms\tremaining: 16.6s\n",
            "20:\tlearn: 59219.2788721\ttotal: 352ms\tremaining: 16.4s\n",
            "21:\tlearn: 59038.2154217\ttotal: 366ms\tremaining: 16.3s\n",
            "22:\tlearn: 58804.6097035\ttotal: 380ms\tremaining: 16.1s\n",
            "23:\tlearn: 58678.3505402\ttotal: 394ms\tremaining: 16s\n",
            "24:\tlearn: 58496.3967974\ttotal: 408ms\tremaining: 15.9s\n",
            "25:\tlearn: 58268.8828275\ttotal: 422ms\tremaining: 15.8s\n",
            "26:\tlearn: 58117.3539090\ttotal: 436ms\tremaining: 15.7s\n",
            "27:\tlearn: 57899.9054395\ttotal: 453ms\tremaining: 15.7s\n",
            "28:\tlearn: 57552.3601837\ttotal: 471ms\tremaining: 15.8s\n",
            "29:\tlearn: 57415.5052048\ttotal: 487ms\tremaining: 15.7s\n",
            "30:\tlearn: 57271.4131695\ttotal: 501ms\tremaining: 15.7s\n",
            "31:\tlearn: 57163.6595676\ttotal: 514ms\tremaining: 15.5s\n",
            "32:\tlearn: 57007.0630721\ttotal: 528ms\tremaining: 15.5s\n",
            "33:\tlearn: 56926.8905110\ttotal: 543ms\tremaining: 15.4s\n",
            "34:\tlearn: 56848.0959923\ttotal: 557ms\tremaining: 15.4s\n",
            "35:\tlearn: 56586.5636022\ttotal: 571ms\tremaining: 15.3s\n",
            "36:\tlearn: 56469.8265675\ttotal: 598ms\tremaining: 15.6s\n",
            "37:\tlearn: 56375.8280738\ttotal: 622ms\tremaining: 15.7s\n",
            "38:\tlearn: 56305.7007490\ttotal: 636ms\tremaining: 15.7s\n",
            "39:\tlearn: 56239.0469956\ttotal: 650ms\tremaining: 15.6s\n",
            "40:\tlearn: 56133.4152742\ttotal: 664ms\tremaining: 15.5s\n",
            "41:\tlearn: 56047.7623696\ttotal: 681ms\tremaining: 15.5s\n",
            "42:\tlearn: 55961.9929271\ttotal: 698ms\tremaining: 15.5s\n",
            "43:\tlearn: 55898.4938056\ttotal: 711ms\tremaining: 15.4s\n",
            "44:\tlearn: 55838.1922838\ttotal: 724ms\tremaining: 15.4s\n",
            "45:\tlearn: 55790.5021018\ttotal: 738ms\tremaining: 15.3s\n",
            "46:\tlearn: 55721.6706087\ttotal: 752ms\tremaining: 15.2s\n",
            "47:\tlearn: 55610.7984459\ttotal: 766ms\tremaining: 15.2s\n",
            "48:\tlearn: 55497.5557164\ttotal: 780ms\tremaining: 15.1s\n",
            "49:\tlearn: 55276.0147912\ttotal: 794ms\tremaining: 15.1s\n",
            "50:\tlearn: 55159.7490387\ttotal: 807ms\tremaining: 15s\n",
            "51:\tlearn: 55045.4701205\ttotal: 821ms\tremaining: 15s\n",
            "52:\tlearn: 54976.1573451\ttotal: 837ms\tremaining: 15s\n",
            "53:\tlearn: 54847.9010383\ttotal: 852ms\tremaining: 14.9s\n",
            "54:\tlearn: 54648.4558099\ttotal: 867ms\tremaining: 14.9s\n",
            "55:\tlearn: 54587.7336433\ttotal: 885ms\tremaining: 14.9s\n",
            "56:\tlearn: 54540.7806061\ttotal: 902ms\tremaining: 14.9s\n",
            "57:\tlearn: 54487.6223631\ttotal: 916ms\tremaining: 14.9s\n",
            "58:\tlearn: 54404.3787360\ttotal: 930ms\tremaining: 14.8s\n",
            "59:\tlearn: 54271.1784913\ttotal: 944ms\tremaining: 14.8s\n",
            "60:\tlearn: 54175.1634483\ttotal: 958ms\tremaining: 14.7s\n",
            "61:\tlearn: 54116.2045072\ttotal: 973ms\tremaining: 14.7s\n",
            "62:\tlearn: 53997.5746556\ttotal: 986ms\tremaining: 14.7s\n",
            "63:\tlearn: 53922.0232588\ttotal: 999ms\tremaining: 14.6s\n",
            "64:\tlearn: 53831.2781321\ttotal: 1.01s\tremaining: 14.6s\n",
            "65:\tlearn: 53758.5252234\ttotal: 1.03s\tremaining: 14.6s\n",
            "66:\tlearn: 53703.0519735\ttotal: 1.04s\tremaining: 14.5s\n",
            "67:\tlearn: 53598.5007316\ttotal: 1.05s\tremaining: 14.5s\n",
            "68:\tlearn: 53524.1251723\ttotal: 1.07s\tremaining: 14.4s\n",
            "69:\tlearn: 53472.9369220\ttotal: 1.08s\tremaining: 14.4s\n",
            "70:\tlearn: 53407.9369284\ttotal: 1.1s\tremaining: 14.4s\n",
            "71:\tlearn: 53337.9989493\ttotal: 1.11s\tremaining: 14.4s\n",
            "72:\tlearn: 53300.4334317\ttotal: 1.13s\tremaining: 14.3s\n",
            "73:\tlearn: 53092.2780017\ttotal: 1.14s\tremaining: 14.3s\n",
            "74:\tlearn: 53034.4597320\ttotal: 1.16s\tremaining: 14.3s\n",
            "75:\tlearn: 53002.5983992\ttotal: 1.17s\tremaining: 14.2s\n",
            "76:\tlearn: 52942.6378715\ttotal: 1.18s\tremaining: 14.2s\n",
            "77:\tlearn: 52859.8675695\ttotal: 1.2s\tremaining: 14.2s\n",
            "78:\tlearn: 52817.5354156\ttotal: 1.21s\tremaining: 14.1s\n",
            "79:\tlearn: 52777.7645403\ttotal: 1.22s\tremaining: 14.1s\n",
            "80:\tlearn: 52683.9182501\ttotal: 1.24s\tremaining: 14s\n",
            "81:\tlearn: 52647.3472376\ttotal: 1.25s\tremaining: 14s\n",
            "82:\tlearn: 52596.4165581\ttotal: 1.26s\tremaining: 14s\n",
            "83:\tlearn: 52548.5077720\ttotal: 1.28s\tremaining: 14s\n",
            "84:\tlearn: 52472.0220719\ttotal: 1.3s\tremaining: 14s\n",
            "85:\tlearn: 52431.7583670\ttotal: 1.32s\tremaining: 14s\n",
            "86:\tlearn: 52356.0461954\ttotal: 1.33s\tremaining: 14s\n",
            "87:\tlearn: 52326.4562049\ttotal: 1.34s\tremaining: 13.9s\n",
            "88:\tlearn: 52244.5980408\ttotal: 1.36s\tremaining: 13.9s\n",
            "89:\tlearn: 52224.2306291\ttotal: 1.37s\tremaining: 13.9s\n",
            "90:\tlearn: 52196.0204378\ttotal: 1.38s\tremaining: 13.8s\n",
            "91:\tlearn: 52149.0293908\ttotal: 1.4s\tremaining: 13.8s\n",
            "92:\tlearn: 52068.7712653\ttotal: 1.41s\tremaining: 13.8s\n",
            "93:\tlearn: 51922.6322223\ttotal: 1.43s\tremaining: 13.8s\n",
            "94:\tlearn: 51880.8740465\ttotal: 1.44s\tremaining: 13.7s\n",
            "95:\tlearn: 51812.2492183\ttotal: 1.45s\tremaining: 13.7s\n",
            "96:\tlearn: 51740.1410803\ttotal: 1.47s\tremaining: 13.7s\n",
            "97:\tlearn: 51689.9927061\ttotal: 1.48s\tremaining: 13.6s\n",
            "98:\tlearn: 51642.1075865\ttotal: 1.5s\tremaining: 13.6s\n",
            "99:\tlearn: 51611.5365723\ttotal: 1.52s\tremaining: 13.7s\n",
            "100:\tlearn: 51573.9598625\ttotal: 1.53s\tremaining: 13.6s\n",
            "101:\tlearn: 51524.6171198\ttotal: 1.54s\tremaining: 13.6s\n",
            "102:\tlearn: 51493.8279321\ttotal: 1.56s\tremaining: 13.6s\n",
            "103:\tlearn: 51431.2104455\ttotal: 1.57s\tremaining: 13.6s\n",
            "104:\tlearn: 51396.1343652\ttotal: 1.59s\tremaining: 13.5s\n",
            "105:\tlearn: 51362.8964047\ttotal: 1.6s\tremaining: 13.5s\n",
            "106:\tlearn: 51327.9661024\ttotal: 1.61s\tremaining: 13.5s\n",
            "107:\tlearn: 51257.6095413\ttotal: 1.63s\tremaining: 13.4s\n",
            "108:\tlearn: 51218.1364801\ttotal: 1.64s\tremaining: 13.4s\n",
            "109:\tlearn: 51199.1686091\ttotal: 1.65s\tremaining: 13.4s\n",
            "110:\tlearn: 51161.8596652\ttotal: 1.67s\tremaining: 13.4s\n",
            "111:\tlearn: 51088.3903628\ttotal: 1.68s\tremaining: 13.3s\n",
            "112:\tlearn: 51028.7083942\ttotal: 1.7s\tremaining: 13.3s\n",
            "113:\tlearn: 50976.7621458\ttotal: 1.71s\tremaining: 13.3s\n",
            "114:\tlearn: 50942.4630712\ttotal: 1.74s\tremaining: 13.4s\n",
            "115:\tlearn: 50903.7346911\ttotal: 1.75s\tremaining: 13.4s\n",
            "116:\tlearn: 50861.7789778\ttotal: 1.77s\tremaining: 13.4s\n",
            "117:\tlearn: 50800.3779710\ttotal: 1.78s\tremaining: 13.3s\n",
            "118:\tlearn: 50770.1324740\ttotal: 1.8s\tremaining: 13.3s\n",
            "119:\tlearn: 50732.0144916\ttotal: 1.81s\tremaining: 13.3s\n",
            "120:\tlearn: 50689.5346675\ttotal: 1.83s\tremaining: 13.3s\n",
            "121:\tlearn: 50655.7603463\ttotal: 1.84s\tremaining: 13.2s\n",
            "122:\tlearn: 50612.1248884\ttotal: 1.85s\tremaining: 13.2s\n",
            "123:\tlearn: 50566.5113489\ttotal: 1.87s\tremaining: 13.2s\n",
            "124:\tlearn: 50519.3215665\ttotal: 1.88s\tremaining: 13.2s\n",
            "125:\tlearn: 50438.8077722\ttotal: 1.9s\tremaining: 13.2s\n",
            "126:\tlearn: 50407.7921820\ttotal: 1.91s\tremaining: 13.1s\n",
            "127:\tlearn: 50343.7547688\ttotal: 1.92s\tremaining: 13.1s\n",
            "128:\tlearn: 50311.5430469\ttotal: 1.94s\tremaining: 13.1s\n",
            "129:\tlearn: 50270.1379919\ttotal: 1.96s\tremaining: 13.1s\n",
            "130:\tlearn: 50236.4888307\ttotal: 1.97s\tremaining: 13.1s\n",
            "131:\tlearn: 50201.1044683\ttotal: 1.99s\tremaining: 13.1s\n",
            "132:\tlearn: 50162.0125527\ttotal: 2s\tremaining: 13s\n",
            "133:\tlearn: 50090.3639080\ttotal: 2.02s\tremaining: 13s\n",
            "134:\tlearn: 50065.9587783\ttotal: 2.03s\tremaining: 13s\n",
            "135:\tlearn: 50038.0009659\ttotal: 2.04s\tremaining: 13s\n",
            "136:\tlearn: 49991.0008955\ttotal: 2.06s\tremaining: 13s\n",
            "137:\tlearn: 49938.0647109\ttotal: 2.07s\tremaining: 12.9s\n",
            "138:\tlearn: 49908.8155753\ttotal: 2.08s\tremaining: 12.9s\n",
            "139:\tlearn: 49875.5103350\ttotal: 2.1s\tremaining: 12.9s\n",
            "140:\tlearn: 49837.1854747\ttotal: 2.11s\tremaining: 12.9s\n",
            "141:\tlearn: 49798.9462543\ttotal: 2.13s\tremaining: 12.9s\n",
            "142:\tlearn: 49733.8550053\ttotal: 2.14s\tremaining: 12.8s\n",
            "143:\tlearn: 49701.2509763\ttotal: 2.15s\tremaining: 12.8s\n",
            "144:\tlearn: 49681.5950780\ttotal: 2.18s\tremaining: 12.8s\n",
            "145:\tlearn: 49650.8242182\ttotal: 2.19s\tremaining: 12.8s\n",
            "146:\tlearn: 49617.8133278\ttotal: 2.21s\tremaining: 12.8s\n",
            "147:\tlearn: 49588.9719056\ttotal: 2.22s\tremaining: 12.8s\n",
            "148:\tlearn: 49566.2330543\ttotal: 2.23s\tremaining: 12.8s\n",
            "149:\tlearn: 49539.3275868\ttotal: 2.25s\tremaining: 12.7s\n",
            "150:\tlearn: 49518.7838185\ttotal: 2.26s\tremaining: 12.7s\n",
            "151:\tlearn: 49494.7254877\ttotal: 2.27s\tremaining: 12.7s\n",
            "152:\tlearn: 49436.0500344\ttotal: 2.29s\tremaining: 12.7s\n",
            "153:\tlearn: 49386.7836726\ttotal: 2.3s\tremaining: 12.6s\n",
            "154:\tlearn: 49358.0081621\ttotal: 2.31s\tremaining: 12.6s\n",
            "155:\tlearn: 49335.6033894\ttotal: 2.33s\tremaining: 12.6s\n",
            "156:\tlearn: 49316.2506470\ttotal: 2.34s\tremaining: 12.6s\n",
            "157:\tlearn: 49277.2265435\ttotal: 2.36s\tremaining: 12.6s\n",
            "158:\tlearn: 49224.9899633\ttotal: 2.37s\tremaining: 12.6s\n",
            "159:\tlearn: 49190.2494997\ttotal: 2.39s\tremaining: 12.6s\n",
            "160:\tlearn: 49122.4594754\ttotal: 2.41s\tremaining: 12.6s\n",
            "161:\tlearn: 49106.8583269\ttotal: 2.42s\tremaining: 12.5s\n",
            "162:\tlearn: 49085.1469096\ttotal: 2.44s\tremaining: 12.5s\n",
            "163:\tlearn: 49050.5586726\ttotal: 2.45s\tremaining: 12.5s\n",
            "164:\tlearn: 49035.6868222\ttotal: 2.46s\tremaining: 12.5s\n",
            "165:\tlearn: 49007.2224679\ttotal: 2.48s\tremaining: 12.5s\n",
            "166:\tlearn: 48971.6890628\ttotal: 2.49s\tremaining: 12.4s\n",
            "167:\tlearn: 48943.2442814\ttotal: 2.51s\tremaining: 12.4s\n",
            "168:\tlearn: 48907.7212589\ttotal: 2.52s\tremaining: 12.4s\n",
            "169:\tlearn: 48880.6633694\ttotal: 2.54s\tremaining: 12.4s\n",
            "170:\tlearn: 48856.8734106\ttotal: 2.55s\tremaining: 12.4s\n",
            "171:\tlearn: 48834.5777897\ttotal: 2.56s\tremaining: 12.3s\n",
            "172:\tlearn: 48815.5059808\ttotal: 2.58s\tremaining: 12.3s\n",
            "173:\tlearn: 48787.3279475\ttotal: 2.59s\tremaining: 12.3s\n",
            "174:\tlearn: 48750.0636866\ttotal: 2.62s\tremaining: 12.3s\n",
            "175:\tlearn: 48685.4840390\ttotal: 2.63s\tremaining: 12.3s\n",
            "176:\tlearn: 48652.4186828\ttotal: 2.64s\tremaining: 12.3s\n",
            "177:\tlearn: 48606.5286749\ttotal: 2.66s\tremaining: 12.3s\n",
            "178:\tlearn: 48581.3844671\ttotal: 2.67s\tremaining: 12.3s\n",
            "179:\tlearn: 48565.6161756\ttotal: 2.69s\tremaining: 12.2s\n",
            "180:\tlearn: 48535.1737836\ttotal: 2.7s\tremaining: 12.2s\n",
            "181:\tlearn: 48503.5423092\ttotal: 2.71s\tremaining: 12.2s\n",
            "182:\tlearn: 48480.5092463\ttotal: 2.73s\tremaining: 12.2s\n",
            "183:\tlearn: 48453.0020304\ttotal: 2.74s\tremaining: 12.2s\n",
            "184:\tlearn: 48436.1688803\ttotal: 2.75s\tremaining: 12.1s\n",
            "185:\tlearn: 48405.0485065\ttotal: 2.77s\tremaining: 12.1s\n",
            "186:\tlearn: 48369.2282130\ttotal: 2.78s\tremaining: 12.1s\n",
            "187:\tlearn: 48321.9072723\ttotal: 2.79s\tremaining: 12.1s\n",
            "188:\tlearn: 48288.2654625\ttotal: 2.81s\tremaining: 12.1s\n",
            "189:\tlearn: 48264.8761722\ttotal: 2.83s\tremaining: 12.1s\n",
            "190:\tlearn: 48229.5260903\ttotal: 2.85s\tremaining: 12.1s\n",
            "191:\tlearn: 48216.6615712\ttotal: 2.86s\tremaining: 12s\n",
            "192:\tlearn: 48190.2049330\ttotal: 2.88s\tremaining: 12s\n",
            "193:\tlearn: 48168.3906505\ttotal: 2.89s\tremaining: 12s\n",
            "194:\tlearn: 48133.2637531\ttotal: 2.9s\tremaining: 12s\n",
            "195:\tlearn: 48103.4027740\ttotal: 2.92s\tremaining: 12s\n",
            "196:\tlearn: 48079.9277874\ttotal: 2.93s\tremaining: 11.9s\n",
            "197:\tlearn: 48042.0513289\ttotal: 2.94s\tremaining: 11.9s\n",
            "198:\tlearn: 47998.0324754\ttotal: 2.96s\tremaining: 11.9s\n",
            "199:\tlearn: 47976.5937936\ttotal: 2.97s\tremaining: 11.9s\n",
            "200:\tlearn: 47958.3939149\ttotal: 2.99s\tremaining: 11.9s\n",
            "201:\tlearn: 47922.4445389\ttotal: 3s\tremaining: 11.9s\n",
            "202:\tlearn: 47847.5039015\ttotal: 3.01s\tremaining: 11.8s\n",
            "203:\tlearn: 47809.4103334\ttotal: 3.03s\tremaining: 11.8s\n",
            "204:\tlearn: 47744.7605392\ttotal: 3.05s\tremaining: 11.8s\n",
            "205:\tlearn: 47720.8447873\ttotal: 3.06s\tremaining: 11.8s\n",
            "206:\tlearn: 47692.2965293\ttotal: 3.08s\tremaining: 11.8s\n",
            "207:\tlearn: 47650.7886851\ttotal: 3.09s\tremaining: 11.8s\n",
            "208:\tlearn: 47624.5542187\ttotal: 3.11s\tremaining: 11.8s\n",
            "209:\tlearn: 47596.0709092\ttotal: 3.12s\tremaining: 11.7s\n",
            "210:\tlearn: 47558.5881490\ttotal: 3.13s\tremaining: 11.7s\n",
            "211:\tlearn: 47520.3977363\ttotal: 3.15s\tremaining: 11.7s\n",
            "212:\tlearn: 47499.8733576\ttotal: 3.16s\tremaining: 11.7s\n",
            "213:\tlearn: 47450.9636563\ttotal: 3.18s\tremaining: 11.7s\n",
            "214:\tlearn: 47413.9517821\ttotal: 3.19s\tremaining: 11.7s\n",
            "215:\tlearn: 47387.6264202\ttotal: 3.21s\tremaining: 11.6s\n",
            "216:\tlearn: 47374.7464140\ttotal: 3.22s\tremaining: 11.6s\n",
            "217:\tlearn: 47358.5055615\ttotal: 3.24s\tremaining: 11.6s\n",
            "218:\tlearn: 47342.2090849\ttotal: 3.26s\tremaining: 11.6s\n",
            "219:\tlearn: 47329.4676861\ttotal: 3.27s\tremaining: 11.6s\n",
            "220:\tlearn: 47286.5570068\ttotal: 3.29s\tremaining: 11.6s\n",
            "221:\tlearn: 47267.2343520\ttotal: 3.3s\tremaining: 11.6s\n",
            "222:\tlearn: 47225.4047002\ttotal: 3.31s\tremaining: 11.6s\n",
            "223:\tlearn: 47199.8683469\ttotal: 3.33s\tremaining: 11.5s\n",
            "224:\tlearn: 47176.0667138\ttotal: 3.34s\tremaining: 11.5s\n",
            "225:\tlearn: 47160.9995182\ttotal: 3.36s\tremaining: 11.5s\n",
            "226:\tlearn: 47145.4194701\ttotal: 3.37s\tremaining: 11.5s\n",
            "227:\tlearn: 47120.8992418\ttotal: 3.38s\tremaining: 11.5s\n",
            "228:\tlearn: 47094.5954094\ttotal: 3.4s\tremaining: 11.4s\n",
            "229:\tlearn: 47073.7172012\ttotal: 3.41s\tremaining: 11.4s\n",
            "230:\tlearn: 47042.1382113\ttotal: 3.43s\tremaining: 11.4s\n",
            "231:\tlearn: 47020.1027221\ttotal: 3.44s\tremaining: 11.4s\n",
            "232:\tlearn: 46994.8684818\ttotal: 3.46s\tremaining: 11.4s\n",
            "233:\tlearn: 46959.7473077\ttotal: 3.47s\tremaining: 11.4s\n",
            "234:\tlearn: 46929.6384663\ttotal: 3.49s\tremaining: 11.3s\n",
            "235:\tlearn: 46907.0390948\ttotal: 3.5s\tremaining: 11.3s\n",
            "236:\tlearn: 46887.8832766\ttotal: 3.51s\tremaining: 11.3s\n",
            "237:\tlearn: 46856.7731666\ttotal: 3.53s\tremaining: 11.3s\n",
            "238:\tlearn: 46837.1059931\ttotal: 3.54s\tremaining: 11.3s\n",
            "239:\tlearn: 46806.2853023\ttotal: 3.56s\tremaining: 11.3s\n",
            "240:\tlearn: 46777.9851089\ttotal: 3.57s\tremaining: 11.2s\n",
            "241:\tlearn: 46741.9350548\ttotal: 3.58s\tremaining: 11.2s\n",
            "242:\tlearn: 46708.7494959\ttotal: 3.6s\tremaining: 11.2s\n",
            "243:\tlearn: 46677.5283018\ttotal: 3.61s\tremaining: 11.2s\n",
            "244:\tlearn: 46660.8728864\ttotal: 3.63s\tremaining: 11.2s\n",
            "245:\tlearn: 46642.9001165\ttotal: 3.64s\tremaining: 11.2s\n",
            "246:\tlearn: 46612.8792509\ttotal: 3.66s\tremaining: 11.2s\n",
            "247:\tlearn: 46573.5689597\ttotal: 3.68s\tremaining: 11.2s\n",
            "248:\tlearn: 46558.4046633\ttotal: 3.69s\tremaining: 11.1s\n",
            "249:\tlearn: 46541.1837662\ttotal: 3.71s\tremaining: 11.1s\n",
            "250:\tlearn: 46531.4541200\ttotal: 3.72s\tremaining: 11.1s\n",
            "251:\tlearn: 46511.4343093\ttotal: 3.73s\tremaining: 11.1s\n",
            "252:\tlearn: 46494.3062845\ttotal: 3.75s\tremaining: 11.1s\n",
            "253:\tlearn: 46465.4382272\ttotal: 3.76s\tremaining: 11s\n",
            "254:\tlearn: 46428.1838414\ttotal: 3.77s\tremaining: 11s\n",
            "255:\tlearn: 46404.8745548\ttotal: 3.79s\tremaining: 11s\n",
            "256:\tlearn: 46385.3503637\ttotal: 3.8s\tremaining: 11s\n",
            "257:\tlearn: 46347.8334935\ttotal: 3.81s\tremaining: 11s\n",
            "258:\tlearn: 46337.5358539\ttotal: 3.83s\tremaining: 10.9s\n",
            "259:\tlearn: 46313.6017866\ttotal: 3.84s\tremaining: 10.9s\n",
            "260:\tlearn: 46297.8607699\ttotal: 3.85s\tremaining: 10.9s\n",
            "261:\tlearn: 46284.6909432\ttotal: 3.88s\tremaining: 10.9s\n",
            "262:\tlearn: 46275.1643260\ttotal: 3.89s\tremaining: 10.9s\n",
            "263:\tlearn: 46259.6887763\ttotal: 3.9s\tremaining: 10.9s\n",
            "264:\tlearn: 46243.9259876\ttotal: 3.92s\tremaining: 10.9s\n",
            "265:\tlearn: 46219.2577687\ttotal: 3.93s\tremaining: 10.8s\n",
            "266:\tlearn: 46200.3500151\ttotal: 3.94s\tremaining: 10.8s\n",
            "267:\tlearn: 46172.3750079\ttotal: 3.96s\tremaining: 10.8s\n",
            "268:\tlearn: 46153.0007145\ttotal: 3.97s\tremaining: 10.8s\n",
            "269:\tlearn: 46132.1752799\ttotal: 3.99s\tremaining: 10.8s\n",
            "270:\tlearn: 46113.0758057\ttotal: 4s\tremaining: 10.8s\n",
            "271:\tlearn: 46085.3389192\ttotal: 4.01s\tremaining: 10.7s\n",
            "272:\tlearn: 46064.7591527\ttotal: 4.03s\tremaining: 10.7s\n",
            "273:\tlearn: 46018.6516533\ttotal: 4.04s\tremaining: 10.7s\n",
            "274:\tlearn: 45995.4201120\ttotal: 4.05s\tremaining: 10.7s\n",
            "275:\tlearn: 45986.0665827\ttotal: 4.07s\tremaining: 10.7s\n",
            "276:\tlearn: 45971.3706009\ttotal: 4.09s\tremaining: 10.7s\n",
            "277:\tlearn: 45959.1286241\ttotal: 4.11s\tremaining: 10.7s\n",
            "278:\tlearn: 45938.5164790\ttotal: 4.12s\tremaining: 10.7s\n",
            "279:\tlearn: 45919.1034773\ttotal: 4.14s\tremaining: 10.6s\n",
            "280:\tlearn: 45894.0269541\ttotal: 4.15s\tremaining: 10.6s\n",
            "281:\tlearn: 45866.9139585\ttotal: 4.17s\tremaining: 10.6s\n",
            "282:\tlearn: 45859.5538093\ttotal: 4.18s\tremaining: 10.6s\n",
            "283:\tlearn: 45837.7313446\ttotal: 4.19s\tremaining: 10.6s\n",
            "284:\tlearn: 45823.1471052\ttotal: 4.21s\tremaining: 10.6s\n",
            "285:\tlearn: 45804.4065917\ttotal: 4.22s\tremaining: 10.5s\n",
            "286:\tlearn: 45780.9651739\ttotal: 4.23s\tremaining: 10.5s\n",
            "287:\tlearn: 45759.1553494\ttotal: 4.25s\tremaining: 10.5s\n",
            "288:\tlearn: 45727.8042603\ttotal: 4.26s\tremaining: 10.5s\n",
            "289:\tlearn: 45678.7752573\ttotal: 4.28s\tremaining: 10.5s\n",
            "290:\tlearn: 45641.5953090\ttotal: 4.29s\tremaining: 10.4s\n",
            "291:\tlearn: 45619.8466461\ttotal: 4.31s\tremaining: 10.5s\n",
            "292:\tlearn: 45605.8531643\ttotal: 4.33s\tremaining: 10.4s\n",
            "293:\tlearn: 45589.3518460\ttotal: 4.34s\tremaining: 10.4s\n",
            "294:\tlearn: 45549.7863035\ttotal: 4.35s\tremaining: 10.4s\n",
            "295:\tlearn: 45539.1556529\ttotal: 4.37s\tremaining: 10.4s\n",
            "296:\tlearn: 45523.6972744\ttotal: 4.38s\tremaining: 10.4s\n",
            "297:\tlearn: 45496.5749414\ttotal: 4.39s\tremaining: 10.3s\n",
            "298:\tlearn: 45488.4473336\ttotal: 4.41s\tremaining: 10.3s\n",
            "299:\tlearn: 45476.3213404\ttotal: 4.42s\tremaining: 10.3s\n",
            "300:\tlearn: 45462.3288906\ttotal: 4.43s\tremaining: 10.3s\n",
            "301:\tlearn: 45451.0399042\ttotal: 4.45s\tremaining: 10.3s\n",
            "302:\tlearn: 45436.7271325\ttotal: 4.46s\tremaining: 10.3s\n",
            "303:\tlearn: 45428.5524854\ttotal: 4.48s\tremaining: 10.2s\n",
            "304:\tlearn: 45412.0812139\ttotal: 4.49s\tremaining: 10.2s\n",
            "305:\tlearn: 45393.8512318\ttotal: 4.5s\tremaining: 10.2s\n",
            "306:\tlearn: 45367.3807045\ttotal: 4.52s\tremaining: 10.2s\n",
            "307:\tlearn: 45361.0945717\ttotal: 4.54s\tremaining: 10.2s\n",
            "308:\tlearn: 45336.5889617\ttotal: 4.55s\tremaining: 10.2s\n",
            "309:\tlearn: 45305.4421027\ttotal: 4.57s\tremaining: 10.2s\n",
            "310:\tlearn: 45288.7220139\ttotal: 4.58s\tremaining: 10.2s\n",
            "311:\tlearn: 45266.1871593\ttotal: 4.59s\tremaining: 10.1s\n",
            "312:\tlearn: 45242.7218626\ttotal: 4.61s\tremaining: 10.1s\n",
            "313:\tlearn: 45210.8886100\ttotal: 4.62s\tremaining: 10.1s\n",
            "314:\tlearn: 45193.4242447\ttotal: 4.63s\tremaining: 10.1s\n",
            "315:\tlearn: 45170.0221276\ttotal: 4.65s\tremaining: 10.1s\n",
            "316:\tlearn: 45152.2916370\ttotal: 4.66s\tremaining: 10s\n",
            "317:\tlearn: 45102.3903349\ttotal: 4.68s\tremaining: 10s\n",
            "318:\tlearn: 45082.2053444\ttotal: 4.69s\tremaining: 10s\n",
            "319:\tlearn: 45062.4655170\ttotal: 4.71s\tremaining: 10s\n",
            "320:\tlearn: 45043.4472723\ttotal: 4.72s\tremaining: 9.99s\n",
            "321:\tlearn: 45023.2540458\ttotal: 4.74s\tremaining: 9.98s\n",
            "322:\tlearn: 44992.4608292\ttotal: 4.76s\tremaining: 9.97s\n",
            "323:\tlearn: 44977.3465654\ttotal: 4.77s\tremaining: 9.96s\n",
            "324:\tlearn: 44960.7368047\ttotal: 4.79s\tremaining: 9.94s\n",
            "325:\tlearn: 44890.7015123\ttotal: 4.8s\tremaining: 9.92s\n",
            "326:\tlearn: 44873.0193982\ttotal: 4.81s\tremaining: 9.91s\n",
            "327:\tlearn: 44859.0122722\ttotal: 4.83s\tremaining: 9.89s\n",
            "328:\tlearn: 44826.3934649\ttotal: 4.84s\tremaining: 9.88s\n",
            "329:\tlearn: 44806.0792059\ttotal: 4.86s\tremaining: 9.86s\n",
            "330:\tlearn: 44789.7717953\ttotal: 4.87s\tremaining: 9.85s\n",
            "331:\tlearn: 44772.5628098\ttotal: 4.89s\tremaining: 9.83s\n",
            "332:\tlearn: 44748.1347501\ttotal: 4.9s\tremaining: 9.81s\n",
            "333:\tlearn: 44713.0165114\ttotal: 4.91s\tremaining: 9.8s\n",
            "334:\tlearn: 44703.1568753\ttotal: 4.93s\tremaining: 9.78s\n",
            "335:\tlearn: 44689.5501758\ttotal: 4.94s\tremaining: 9.77s\n",
            "336:\tlearn: 44663.2918086\ttotal: 4.96s\tremaining: 9.77s\n",
            "337:\tlearn: 44658.4532159\ttotal: 4.98s\tremaining: 9.75s\n",
            "338:\tlearn: 44645.2946757\ttotal: 4.99s\tremaining: 9.73s\n",
            "339:\tlearn: 44615.1903520\ttotal: 5.01s\tremaining: 9.72s\n",
            "340:\tlearn: 44603.1399736\ttotal: 5.02s\tremaining: 9.7s\n",
            "341:\tlearn: 44587.5504480\ttotal: 5.03s\tremaining: 9.69s\n",
            "342:\tlearn: 44573.2065296\ttotal: 5.05s\tremaining: 9.67s\n",
            "343:\tlearn: 44541.0158573\ttotal: 5.06s\tremaining: 9.65s\n",
            "344:\tlearn: 44519.9219714\ttotal: 5.08s\tremaining: 9.63s\n",
            "345:\tlearn: 44509.2094541\ttotal: 5.09s\tremaining: 9.62s\n",
            "346:\tlearn: 44468.1736165\ttotal: 5.1s\tremaining: 9.6s\n",
            "347:\tlearn: 44450.3285267\ttotal: 5.12s\tremaining: 9.59s\n",
            "348:\tlearn: 44423.4358595\ttotal: 5.13s\tremaining: 9.57s\n",
            "349:\tlearn: 44413.7304400\ttotal: 5.15s\tremaining: 9.57s\n",
            "350:\tlearn: 44396.6872275\ttotal: 5.17s\tremaining: 9.55s\n",
            "351:\tlearn: 44372.3067298\ttotal: 5.18s\tremaining: 9.54s\n",
            "352:\tlearn: 44346.6852503\ttotal: 5.19s\tremaining: 9.52s\n",
            "353:\tlearn: 44321.7835768\ttotal: 5.21s\tremaining: 9.51s\n",
            "354:\tlearn: 44301.9146283\ttotal: 5.22s\tremaining: 9.49s\n",
            "355:\tlearn: 44285.3916754\ttotal: 5.24s\tremaining: 9.47s\n",
            "356:\tlearn: 44264.2607804\ttotal: 5.25s\tremaining: 9.46s\n",
            "357:\tlearn: 44254.9488572\ttotal: 5.26s\tremaining: 9.44s\n",
            "358:\tlearn: 44242.7604752\ttotal: 5.28s\tremaining: 9.43s\n",
            "359:\tlearn: 44225.9827667\ttotal: 5.29s\tremaining: 9.41s\n",
            "360:\tlearn: 44209.2398426\ttotal: 5.31s\tremaining: 9.39s\n",
            "361:\tlearn: 44187.2763685\ttotal: 5.32s\tremaining: 9.38s\n",
            "362:\tlearn: 44176.7173297\ttotal: 5.34s\tremaining: 9.37s\n",
            "363:\tlearn: 44160.4275427\ttotal: 5.35s\tremaining: 9.35s\n",
            "364:\tlearn: 44128.3895805\ttotal: 5.37s\tremaining: 9.35s\n",
            "365:\tlearn: 44103.0415242\ttotal: 5.39s\tremaining: 9.33s\n",
            "366:\tlearn: 44082.4059920\ttotal: 5.4s\tremaining: 9.31s\n",
            "367:\tlearn: 44071.9269160\ttotal: 5.41s\tremaining: 9.3s\n",
            "368:\tlearn: 44052.3673703\ttotal: 5.43s\tremaining: 9.28s\n",
            "369:\tlearn: 44032.3830375\ttotal: 5.44s\tremaining: 9.27s\n",
            "370:\tlearn: 44016.5954527\ttotal: 5.46s\tremaining: 9.25s\n",
            "371:\tlearn: 44008.0491606\ttotal: 5.47s\tremaining: 9.23s\n",
            "372:\tlearn: 43992.5787547\ttotal: 5.48s\tremaining: 9.22s\n",
            "373:\tlearn: 43972.1326698\ttotal: 5.5s\tremaining: 9.2s\n",
            "374:\tlearn: 43952.9150236\ttotal: 5.51s\tremaining: 9.19s\n",
            "375:\tlearn: 43934.3915412\ttotal: 5.53s\tremaining: 9.17s\n",
            "376:\tlearn: 43926.7651187\ttotal: 5.54s\tremaining: 9.15s\n",
            "377:\tlearn: 43915.5422016\ttotal: 5.56s\tremaining: 9.15s\n",
            "378:\tlearn: 43891.0407383\ttotal: 5.58s\tremaining: 9.14s\n",
            "379:\tlearn: 43866.4220807\ttotal: 5.59s\tremaining: 9.12s\n",
            "380:\tlearn: 43846.1829038\ttotal: 5.61s\tremaining: 9.11s\n",
            "381:\tlearn: 43835.9754376\ttotal: 5.62s\tremaining: 9.09s\n",
            "382:\tlearn: 43824.5006719\ttotal: 5.63s\tremaining: 9.07s\n",
            "383:\tlearn: 43807.7751253\ttotal: 5.65s\tremaining: 9.06s\n",
            "384:\tlearn: 43790.6793378\ttotal: 5.66s\tremaining: 9.04s\n",
            "385:\tlearn: 43777.4861486\ttotal: 5.67s\tremaining: 9.03s\n",
            "386:\tlearn: 43756.5839097\ttotal: 5.69s\tremaining: 9.01s\n",
            "387:\tlearn: 43725.1909924\ttotal: 5.7s\tremaining: 8.99s\n",
            "388:\tlearn: 43715.2095322\ttotal: 5.71s\tremaining: 8.98s\n",
            "389:\tlearn: 43693.4916516\ttotal: 5.73s\tremaining: 8.96s\n",
            "390:\tlearn: 43676.9725919\ttotal: 5.74s\tremaining: 8.95s\n",
            "391:\tlearn: 43659.9589719\ttotal: 5.76s\tremaining: 8.93s\n",
            "392:\tlearn: 43639.2364496\ttotal: 5.78s\tremaining: 8.93s\n",
            "393:\tlearn: 43628.4649214\ttotal: 5.79s\tremaining: 8.91s\n",
            "394:\tlearn: 43617.6586830\ttotal: 5.81s\tremaining: 8.89s\n",
            "395:\tlearn: 43606.2733710\ttotal: 5.82s\tremaining: 8.88s\n",
            "396:\tlearn: 43592.5440532\ttotal: 5.83s\tremaining: 8.86s\n",
            "397:\tlearn: 43577.2795406\ttotal: 5.85s\tremaining: 8.85s\n",
            "398:\tlearn: 43562.5870888\ttotal: 5.86s\tremaining: 8.83s\n",
            "399:\tlearn: 43531.3156939\ttotal: 5.88s\tremaining: 8.81s\n",
            "400:\tlearn: 43509.8760691\ttotal: 5.89s\tremaining: 8.8s\n",
            "401:\tlearn: 43494.9136833\ttotal: 5.91s\tremaining: 8.79s\n",
            "402:\tlearn: 43478.0547046\ttotal: 5.92s\tremaining: 8.77s\n",
            "403:\tlearn: 43452.9724200\ttotal: 5.93s\tremaining: 8.75s\n",
            "404:\tlearn: 43438.0194222\ttotal: 5.95s\tremaining: 8.74s\n",
            "405:\tlearn: 43400.6580789\ttotal: 5.96s\tremaining: 8.72s\n",
            "406:\tlearn: 43380.1138773\ttotal: 5.97s\tremaining: 8.71s\n",
            "407:\tlearn: 43369.0233375\ttotal: 6s\tremaining: 8.71s\n",
            "408:\tlearn: 43355.2734595\ttotal: 6.01s\tremaining: 8.69s\n",
            "409:\tlearn: 43341.0284251\ttotal: 6.03s\tremaining: 8.68s\n",
            "410:\tlearn: 43317.6384337\ttotal: 6.04s\tremaining: 8.66s\n",
            "411:\tlearn: 43304.3413153\ttotal: 6.06s\tremaining: 8.64s\n",
            "412:\tlearn: 43290.8680868\ttotal: 6.07s\tremaining: 8.63s\n",
            "413:\tlearn: 43257.5049388\ttotal: 6.08s\tremaining: 8.61s\n",
            "414:\tlearn: 43240.3700997\ttotal: 6.1s\tremaining: 8.59s\n",
            "415:\tlearn: 43227.8132146\ttotal: 6.11s\tremaining: 8.58s\n",
            "416:\tlearn: 43210.6908417\ttotal: 6.12s\tremaining: 8.56s\n",
            "417:\tlearn: 43202.4927896\ttotal: 6.14s\tremaining: 8.54s\n",
            "418:\tlearn: 43185.8069796\ttotal: 6.15s\tremaining: 8.53s\n",
            "419:\tlearn: 43172.1295874\ttotal: 6.17s\tremaining: 8.51s\n",
            "420:\tlearn: 43159.3953763\ttotal: 6.18s\tremaining: 8.5s\n",
            "421:\tlearn: 43146.7541803\ttotal: 6.19s\tremaining: 8.48s\n",
            "422:\tlearn: 43133.4970943\ttotal: 6.22s\tremaining: 8.48s\n",
            "423:\tlearn: 43121.6324146\ttotal: 6.23s\tremaining: 8.46s\n",
            "424:\tlearn: 43116.2110691\ttotal: 6.24s\tremaining: 8.45s\n",
            "425:\tlearn: 43105.2032889\ttotal: 6.26s\tremaining: 8.43s\n",
            "426:\tlearn: 43088.0572129\ttotal: 6.27s\tremaining: 8.42s\n",
            "427:\tlearn: 43071.9627648\ttotal: 6.29s\tremaining: 8.4s\n",
            "428:\tlearn: 43054.4018213\ttotal: 6.3s\tremaining: 8.38s\n",
            "429:\tlearn: 43046.3132159\ttotal: 6.31s\tremaining: 8.37s\n",
            "430:\tlearn: 43037.9727547\ttotal: 6.33s\tremaining: 8.36s\n",
            "431:\tlearn: 43026.5138969\ttotal: 6.34s\tremaining: 8.34s\n",
            "432:\tlearn: 42995.3495387\ttotal: 6.36s\tremaining: 8.32s\n",
            "433:\tlearn: 42977.0249696\ttotal: 6.37s\tremaining: 8.31s\n",
            "434:\tlearn: 42953.5965547\ttotal: 6.38s\tremaining: 8.29s\n",
            "435:\tlearn: 42909.0847270\ttotal: 6.4s\tremaining: 8.28s\n",
            "436:\tlearn: 42885.0795415\ttotal: 6.41s\tremaining: 8.26s\n",
            "437:\tlearn: 42872.0811369\ttotal: 6.43s\tremaining: 8.25s\n",
            "438:\tlearn: 42869.2416879\ttotal: 6.45s\tremaining: 8.24s\n",
            "439:\tlearn: 42844.4301370\ttotal: 6.46s\tremaining: 8.22s\n",
            "440:\tlearn: 42815.0097757\ttotal: 6.47s\tremaining: 8.21s\n",
            "441:\tlearn: 42798.4244732\ttotal: 6.49s\tremaining: 8.19s\n",
            "442:\tlearn: 42792.0929941\ttotal: 6.5s\tremaining: 8.17s\n",
            "443:\tlearn: 42778.9116410\ttotal: 6.51s\tremaining: 8.16s\n",
            "444:\tlearn: 42758.8655402\ttotal: 6.53s\tremaining: 8.14s\n",
            "445:\tlearn: 42743.6550474\ttotal: 6.54s\tremaining: 8.13s\n",
            "446:\tlearn: 42716.2844978\ttotal: 6.56s\tremaining: 8.11s\n",
            "447:\tlearn: 42706.6728680\ttotal: 6.57s\tremaining: 8.1s\n",
            "448:\tlearn: 42686.2073923\ttotal: 6.58s\tremaining: 8.08s\n",
            "449:\tlearn: 42677.4352740\ttotal: 6.6s\tremaining: 8.06s\n",
            "450:\tlearn: 42670.2096757\ttotal: 6.61s\tremaining: 8.05s\n",
            "451:\tlearn: 42656.5294082\ttotal: 6.63s\tremaining: 8.03s\n",
            "452:\tlearn: 42630.7866839\ttotal: 6.65s\tremaining: 8.03s\n",
            "453:\tlearn: 42612.4659440\ttotal: 6.67s\tremaining: 8.02s\n",
            "454:\tlearn: 42596.0785651\ttotal: 6.68s\tremaining: 8s\n",
            "455:\tlearn: 42584.6623126\ttotal: 6.7s\tremaining: 7.99s\n",
            "456:\tlearn: 42576.2581095\ttotal: 6.71s\tremaining: 7.97s\n",
            "457:\tlearn: 42558.3547613\ttotal: 6.72s\tremaining: 7.96s\n",
            "458:\tlearn: 42550.8972926\ttotal: 6.74s\tremaining: 7.94s\n",
            "459:\tlearn: 42541.3435306\ttotal: 6.75s\tremaining: 7.92s\n",
            "460:\tlearn: 42525.9752343\ttotal: 6.76s\tremaining: 7.91s\n",
            "461:\tlearn: 42514.4339923\ttotal: 6.78s\tremaining: 7.89s\n",
            "462:\tlearn: 42490.2183328\ttotal: 6.79s\tremaining: 7.88s\n",
            "463:\tlearn: 42471.8430091\ttotal: 6.8s\tremaining: 7.86s\n",
            "464:\tlearn: 42454.8532427\ttotal: 6.82s\tremaining: 7.84s\n",
            "465:\tlearn: 42440.8647809\ttotal: 6.83s\tremaining: 7.83s\n",
            "466:\tlearn: 42429.1279198\ttotal: 6.85s\tremaining: 7.82s\n",
            "467:\tlearn: 42424.4022354\ttotal: 6.87s\tremaining: 7.81s\n",
            "468:\tlearn: 42420.0190160\ttotal: 6.88s\tremaining: 7.8s\n",
            "469:\tlearn: 42408.5700545\ttotal: 6.9s\tremaining: 7.78s\n",
            "470:\tlearn: 42392.8036293\ttotal: 6.91s\tremaining: 7.76s\n",
            "471:\tlearn: 42373.4999381\ttotal: 6.93s\tremaining: 7.75s\n",
            "472:\tlearn: 42349.8417993\ttotal: 6.94s\tremaining: 7.73s\n",
            "473:\tlearn: 42335.1643926\ttotal: 6.95s\tremaining: 7.72s\n",
            "474:\tlearn: 42328.2105029\ttotal: 6.97s\tremaining: 7.7s\n",
            "475:\tlearn: 42303.0751055\ttotal: 6.98s\tremaining: 7.69s\n",
            "476:\tlearn: 42293.0775010\ttotal: 7s\tremaining: 7.67s\n",
            "477:\tlearn: 42275.2570353\ttotal: 7.01s\tremaining: 7.66s\n",
            "478:\tlearn: 42265.0845252\ttotal: 7.03s\tremaining: 7.64s\n",
            "479:\tlearn: 42255.7033104\ttotal: 7.04s\tremaining: 7.63s\n",
            "480:\tlearn: 42245.6358875\ttotal: 7.05s\tremaining: 7.61s\n",
            "481:\tlearn: 42227.6312535\ttotal: 7.07s\tremaining: 7.6s\n",
            "482:\tlearn: 42211.8759135\ttotal: 7.09s\tremaining: 7.59s\n",
            "483:\tlearn: 42183.5067976\ttotal: 7.11s\tremaining: 7.58s\n",
            "484:\tlearn: 42172.8026255\ttotal: 7.12s\tremaining: 7.56s\n",
            "485:\tlearn: 42158.2313572\ttotal: 7.13s\tremaining: 7.54s\n",
            "486:\tlearn: 42147.1930286\ttotal: 7.15s\tremaining: 7.53s\n",
            "487:\tlearn: 42108.0398269\ttotal: 7.16s\tremaining: 7.51s\n",
            "488:\tlearn: 42098.3647010\ttotal: 7.18s\tremaining: 7.5s\n",
            "489:\tlearn: 42084.0296346\ttotal: 7.19s\tremaining: 7.48s\n",
            "490:\tlearn: 42069.3843726\ttotal: 7.2s\tremaining: 7.47s\n",
            "491:\tlearn: 42035.7826136\ttotal: 7.22s\tremaining: 7.45s\n",
            "492:\tlearn: 42014.7489032\ttotal: 7.23s\tremaining: 7.44s\n",
            "493:\tlearn: 42004.0919921\ttotal: 7.25s\tremaining: 7.42s\n",
            "494:\tlearn: 41987.5841807\ttotal: 7.26s\tremaining: 7.41s\n",
            "495:\tlearn: 41979.2568062\ttotal: 7.28s\tremaining: 7.39s\n",
            "496:\tlearn: 41963.2593478\ttotal: 7.3s\tremaining: 7.38s\n",
            "497:\tlearn: 41954.8195785\ttotal: 7.31s\tremaining: 7.37s\n",
            "498:\tlearn: 41943.3692328\ttotal: 7.32s\tremaining: 7.35s\n",
            "499:\tlearn: 41927.3723819\ttotal: 7.34s\tremaining: 7.34s\n",
            "500:\tlearn: 41904.0224790\ttotal: 7.35s\tremaining: 7.32s\n",
            "501:\tlearn: 41892.6973057\ttotal: 7.37s\tremaining: 7.31s\n",
            "502:\tlearn: 41879.3620124\ttotal: 7.38s\tremaining: 7.29s\n",
            "503:\tlearn: 41870.1085685\ttotal: 7.39s\tremaining: 7.28s\n",
            "504:\tlearn: 41857.9755155\ttotal: 7.41s\tremaining: 7.26s\n",
            "505:\tlearn: 41836.2097665\ttotal: 7.42s\tremaining: 7.25s\n",
            "506:\tlearn: 41815.0368074\ttotal: 7.44s\tremaining: 7.23s\n",
            "507:\tlearn: 41804.9235814\ttotal: 7.45s\tremaining: 7.22s\n",
            "508:\tlearn: 41794.8533561\ttotal: 7.46s\tremaining: 7.2s\n",
            "509:\tlearn: 41774.0036155\ttotal: 7.48s\tremaining: 7.18s\n",
            "510:\tlearn: 41764.4334519\ttotal: 7.49s\tremaining: 7.17s\n",
            "511:\tlearn: 41746.4481094\ttotal: 7.51s\tremaining: 7.16s\n",
            "512:\tlearn: 41729.4717649\ttotal: 7.53s\tremaining: 7.15s\n",
            "513:\tlearn: 41715.7696250\ttotal: 7.54s\tremaining: 7.13s\n",
            "514:\tlearn: 41697.3314268\ttotal: 7.56s\tremaining: 7.12s\n",
            "515:\tlearn: 41674.0960503\ttotal: 7.57s\tremaining: 7.1s\n",
            "516:\tlearn: 41658.5132318\ttotal: 7.58s\tremaining: 7.08s\n",
            "517:\tlearn: 41643.6596683\ttotal: 7.6s\tremaining: 7.07s\n",
            "518:\tlearn: 41629.5138448\ttotal: 7.61s\tremaining: 7.05s\n",
            "519:\tlearn: 41614.7890853\ttotal: 7.63s\tremaining: 7.04s\n",
            "520:\tlearn: 41608.1019816\ttotal: 7.64s\tremaining: 7.02s\n",
            "521:\tlearn: 41588.0413350\ttotal: 7.65s\tremaining: 7.01s\n",
            "522:\tlearn: 41577.7336758\ttotal: 7.67s\tremaining: 6.99s\n",
            "523:\tlearn: 41568.4530973\ttotal: 7.68s\tremaining: 6.98s\n",
            "524:\tlearn: 41549.3451472\ttotal: 7.7s\tremaining: 6.96s\n",
            "525:\tlearn: 41515.0374981\ttotal: 7.71s\tremaining: 6.95s\n",
            "526:\tlearn: 41493.3553498\ttotal: 7.74s\tremaining: 6.95s\n",
            "527:\tlearn: 41485.7624376\ttotal: 7.76s\tremaining: 6.93s\n",
            "528:\tlearn: 41450.7265635\ttotal: 7.77s\tremaining: 6.92s\n",
            "529:\tlearn: 41434.1053938\ttotal: 7.79s\tremaining: 6.91s\n",
            "530:\tlearn: 41424.0986036\ttotal: 7.8s\tremaining: 6.89s\n",
            "531:\tlearn: 41403.4480284\ttotal: 7.81s\tremaining: 6.87s\n",
            "532:\tlearn: 41393.6297193\ttotal: 7.83s\tremaining: 6.86s\n",
            "533:\tlearn: 41372.8365315\ttotal: 7.84s\tremaining: 6.84s\n",
            "534:\tlearn: 41356.2807394\ttotal: 7.86s\tremaining: 6.83s\n",
            "535:\tlearn: 41334.2131403\ttotal: 7.87s\tremaining: 6.81s\n",
            "536:\tlearn: 41317.0203455\ttotal: 7.88s\tremaining: 6.8s\n",
            "537:\tlearn: 41306.1001580\ttotal: 7.9s\tremaining: 6.78s\n",
            "538:\tlearn: 41299.4224199\ttotal: 7.91s\tremaining: 6.77s\n",
            "539:\tlearn: 41291.6730595\ttotal: 7.93s\tremaining: 6.75s\n",
            "540:\tlearn: 41282.7103694\ttotal: 7.94s\tremaining: 6.74s\n",
            "541:\tlearn: 41265.1545822\ttotal: 7.96s\tremaining: 6.73s\n",
            "542:\tlearn: 41246.7674859\ttotal: 7.97s\tremaining: 6.71s\n",
            "543:\tlearn: 41221.1243082\ttotal: 7.99s\tremaining: 6.7s\n",
            "544:\tlearn: 41209.6687923\ttotal: 8s\tremaining: 6.68s\n",
            "545:\tlearn: 41198.3163755\ttotal: 8.02s\tremaining: 6.66s\n",
            "546:\tlearn: 41183.7253494\ttotal: 8.03s\tremaining: 6.65s\n",
            "547:\tlearn: 41165.1744911\ttotal: 8.04s\tremaining: 6.63s\n",
            "548:\tlearn: 41143.8681209\ttotal: 8.06s\tremaining: 6.62s\n",
            "549:\tlearn: 41127.8318100\ttotal: 8.07s\tremaining: 6.6s\n",
            "550:\tlearn: 41118.4501191\ttotal: 8.08s\tremaining: 6.59s\n",
            "551:\tlearn: 41097.6433273\ttotal: 8.1s\tremaining: 6.57s\n",
            "552:\tlearn: 41071.3906429\ttotal: 8.11s\tremaining: 6.55s\n",
            "553:\tlearn: 41056.7674053\ttotal: 8.12s\tremaining: 6.54s\n",
            "554:\tlearn: 41047.9481461\ttotal: 8.14s\tremaining: 6.53s\n",
            "555:\tlearn: 41026.2766983\ttotal: 8.15s\tremaining: 6.51s\n",
            "556:\tlearn: 41013.6483527\ttotal: 8.18s\tremaining: 6.5s\n",
            "557:\tlearn: 40992.0673042\ttotal: 8.19s\tremaining: 6.49s\n",
            "558:\tlearn: 40981.6827063\ttotal: 8.2s\tremaining: 6.47s\n",
            "559:\tlearn: 40961.2152215\ttotal: 8.22s\tremaining: 6.46s\n",
            "560:\tlearn: 40944.6561965\ttotal: 8.23s\tremaining: 6.44s\n",
            "561:\tlearn: 40928.9695557\ttotal: 8.24s\tremaining: 6.43s\n",
            "562:\tlearn: 40915.8209130\ttotal: 8.26s\tremaining: 6.41s\n",
            "563:\tlearn: 40909.0070463\ttotal: 8.27s\tremaining: 6.39s\n",
            "564:\tlearn: 40902.0493917\ttotal: 8.29s\tremaining: 6.38s\n",
            "565:\tlearn: 40891.5815755\ttotal: 8.3s\tremaining: 6.36s\n",
            "566:\tlearn: 40879.2399657\ttotal: 8.31s\tremaining: 6.35s\n",
            "567:\tlearn: 40850.9107998\ttotal: 8.33s\tremaining: 6.33s\n",
            "568:\tlearn: 40842.0907001\ttotal: 8.34s\tremaining: 6.32s\n",
            "569:\tlearn: 40829.7827363\ttotal: 8.36s\tremaining: 6.3s\n",
            "570:\tlearn: 40813.3252935\ttotal: 8.37s\tremaining: 6.29s\n",
            "571:\tlearn: 40798.3735515\ttotal: 8.39s\tremaining: 6.28s\n",
            "572:\tlearn: 40786.2230610\ttotal: 8.4s\tremaining: 6.26s\n",
            "573:\tlearn: 40777.7203413\ttotal: 8.42s\tremaining: 6.25s\n",
            "574:\tlearn: 40759.1270380\ttotal: 8.43s\tremaining: 6.23s\n",
            "575:\tlearn: 40747.0844863\ttotal: 8.45s\tremaining: 6.22s\n",
            "576:\tlearn: 40700.5211340\ttotal: 8.46s\tremaining: 6.2s\n",
            "577:\tlearn: 40696.3643276\ttotal: 8.47s\tremaining: 6.19s\n",
            "578:\tlearn: 40691.2508276\ttotal: 8.49s\tremaining: 6.17s\n",
            "579:\tlearn: 40679.6722830\ttotal: 8.5s\tremaining: 6.16s\n",
            "580:\tlearn: 40670.0745299\ttotal: 8.52s\tremaining: 6.14s\n",
            "581:\tlearn: 40657.6225339\ttotal: 8.53s\tremaining: 6.13s\n",
            "582:\tlearn: 40643.4828677\ttotal: 8.54s\tremaining: 6.11s\n",
            "583:\tlearn: 40628.3132712\ttotal: 8.56s\tremaining: 6.1s\n",
            "584:\tlearn: 40620.8191535\ttotal: 8.57s\tremaining: 6.08s\n",
            "585:\tlearn: 40606.0240797\ttotal: 8.59s\tremaining: 6.07s\n",
            "586:\tlearn: 40601.2413052\ttotal: 8.61s\tremaining: 6.06s\n",
            "587:\tlearn: 40563.5289048\ttotal: 8.63s\tremaining: 6.04s\n",
            "588:\tlearn: 40553.4125592\ttotal: 8.64s\tremaining: 6.03s\n",
            "589:\tlearn: 40534.0802599\ttotal: 8.65s\tremaining: 6.01s\n",
            "590:\tlearn: 40518.3018177\ttotal: 8.67s\tremaining: 6s\n",
            "591:\tlearn: 40507.2274438\ttotal: 8.69s\tremaining: 5.99s\n",
            "592:\tlearn: 40492.8415933\ttotal: 8.7s\tremaining: 5.97s\n",
            "593:\tlearn: 40478.2049356\ttotal: 8.71s\tremaining: 5.96s\n",
            "594:\tlearn: 40469.3536681\ttotal: 8.73s\tremaining: 5.94s\n",
            "595:\tlearn: 40448.7089231\ttotal: 8.74s\tremaining: 5.92s\n",
            "596:\tlearn: 40431.9272284\ttotal: 8.75s\tremaining: 5.91s\n",
            "597:\tlearn: 40411.1338071\ttotal: 8.77s\tremaining: 5.89s\n",
            "598:\tlearn: 40391.2851282\ttotal: 8.78s\tremaining: 5.88s\n",
            "599:\tlearn: 40377.3229927\ttotal: 8.8s\tremaining: 5.86s\n",
            "600:\tlearn: 40367.1473865\ttotal: 8.81s\tremaining: 5.85s\n",
            "601:\tlearn: 40352.2233550\ttotal: 8.83s\tremaining: 5.84s\n",
            "602:\tlearn: 40343.2365895\ttotal: 8.84s\tremaining: 5.82s\n",
            "603:\tlearn: 40338.6047714\ttotal: 8.86s\tremaining: 5.81s\n",
            "604:\tlearn: 40323.4601380\ttotal: 8.87s\tremaining: 5.79s\n",
            "605:\tlearn: 40300.8786565\ttotal: 8.88s\tremaining: 5.78s\n",
            "606:\tlearn: 40281.4267915\ttotal: 8.9s\tremaining: 5.76s\n",
            "607:\tlearn: 40268.1160481\ttotal: 8.91s\tremaining: 5.75s\n",
            "608:\tlearn: 40259.4883897\ttotal: 8.93s\tremaining: 5.73s\n",
            "609:\tlearn: 40251.1483409\ttotal: 8.94s\tremaining: 5.72s\n",
            "610:\tlearn: 40242.9664752\ttotal: 8.95s\tremaining: 5.7s\n",
            "611:\tlearn: 40237.2250909\ttotal: 8.97s\tremaining: 5.69s\n",
            "612:\tlearn: 40223.6796518\ttotal: 8.98s\tremaining: 5.67s\n",
            "613:\tlearn: 40213.4285013\ttotal: 9s\tremaining: 5.66s\n",
            "614:\tlearn: 40186.9806475\ttotal: 9.01s\tremaining: 5.64s\n",
            "615:\tlearn: 40174.7283502\ttotal: 9.03s\tremaining: 5.63s\n",
            "616:\tlearn: 40162.6292054\ttotal: 9.05s\tremaining: 5.62s\n",
            "617:\tlearn: 40146.6383661\ttotal: 9.07s\tremaining: 5.61s\n",
            "618:\tlearn: 40126.7431703\ttotal: 9.08s\tremaining: 5.59s\n",
            "619:\tlearn: 40111.9658687\ttotal: 9.1s\tremaining: 5.58s\n",
            "620:\tlearn: 40085.8343743\ttotal: 9.11s\tremaining: 5.56s\n",
            "621:\tlearn: 40069.5400470\ttotal: 9.13s\tremaining: 5.55s\n",
            "622:\tlearn: 40059.9712941\ttotal: 9.14s\tremaining: 5.53s\n",
            "623:\tlearn: 40043.6297947\ttotal: 9.16s\tremaining: 5.52s\n",
            "624:\tlearn: 40034.6251442\ttotal: 9.17s\tremaining: 5.5s\n",
            "625:\tlearn: 40017.6971178\ttotal: 9.19s\tremaining: 5.49s\n",
            "626:\tlearn: 40007.1471929\ttotal: 9.2s\tremaining: 5.47s\n",
            "627:\tlearn: 39985.5361570\ttotal: 9.22s\tremaining: 5.46s\n",
            "628:\tlearn: 39975.5947688\ttotal: 9.23s\tremaining: 5.44s\n",
            "629:\tlearn: 39940.7586409\ttotal: 9.25s\tremaining: 5.43s\n",
            "630:\tlearn: 39922.9960626\ttotal: 9.26s\tremaining: 5.42s\n",
            "631:\tlearn: 39909.5416135\ttotal: 9.28s\tremaining: 5.4s\n",
            "632:\tlearn: 39902.5560633\ttotal: 9.29s\tremaining: 5.39s\n",
            "633:\tlearn: 39876.0139145\ttotal: 9.31s\tremaining: 5.37s\n",
            "634:\tlearn: 39865.4568254\ttotal: 9.32s\tremaining: 5.36s\n",
            "635:\tlearn: 39852.7425749\ttotal: 9.33s\tremaining: 5.34s\n",
            "636:\tlearn: 39847.0220643\ttotal: 9.35s\tremaining: 5.33s\n",
            "637:\tlearn: 39833.5083749\ttotal: 9.36s\tremaining: 5.31s\n",
            "638:\tlearn: 39817.7973017\ttotal: 9.38s\tremaining: 5.3s\n",
            "639:\tlearn: 39805.8944252\ttotal: 9.39s\tremaining: 5.28s\n",
            "640:\tlearn: 39788.2705497\ttotal: 9.41s\tremaining: 5.27s\n",
            "641:\tlearn: 39775.9977347\ttotal: 9.42s\tremaining: 5.25s\n",
            "642:\tlearn: 39741.2710268\ttotal: 9.44s\tremaining: 5.24s\n",
            "643:\tlearn: 39729.8603973\ttotal: 9.46s\tremaining: 5.23s\n",
            "644:\tlearn: 39711.0814575\ttotal: 9.48s\tremaining: 5.21s\n",
            "645:\tlearn: 39699.2761383\ttotal: 9.49s\tremaining: 5.2s\n",
            "646:\tlearn: 39689.4918776\ttotal: 9.5s\tremaining: 5.18s\n",
            "647:\tlearn: 39669.8813108\ttotal: 9.52s\tremaining: 5.17s\n",
            "648:\tlearn: 39646.1253358\ttotal: 9.53s\tremaining: 5.16s\n",
            "649:\tlearn: 39634.5095597\ttotal: 9.54s\tremaining: 5.14s\n",
            "650:\tlearn: 39622.3731259\ttotal: 9.56s\tremaining: 5.13s\n",
            "651:\tlearn: 39610.7614834\ttotal: 9.57s\tremaining: 5.11s\n",
            "652:\tlearn: 39592.4917532\ttotal: 9.59s\tremaining: 5.09s\n",
            "653:\tlearn: 39579.5381063\ttotal: 9.6s\tremaining: 5.08s\n",
            "654:\tlearn: 39557.5730815\ttotal: 9.61s\tremaining: 5.06s\n",
            "655:\tlearn: 39544.5637999\ttotal: 9.63s\tremaining: 5.05s\n",
            "656:\tlearn: 39535.5235651\ttotal: 9.64s\tremaining: 5.03s\n",
            "657:\tlearn: 39520.7085881\ttotal: 9.66s\tremaining: 5.02s\n",
            "658:\tlearn: 39506.3359541\ttotal: 9.67s\tremaining: 5.01s\n",
            "659:\tlearn: 39487.6568244\ttotal: 9.69s\tremaining: 4.99s\n",
            "660:\tlearn: 39462.6187770\ttotal: 9.7s\tremaining: 4.98s\n",
            "661:\tlearn: 39452.2377615\ttotal: 9.72s\tremaining: 4.96s\n",
            "662:\tlearn: 39445.8536991\ttotal: 9.73s\tremaining: 4.95s\n",
            "663:\tlearn: 39436.1142455\ttotal: 9.74s\tremaining: 4.93s\n",
            "664:\tlearn: 39421.9171083\ttotal: 9.76s\tremaining: 4.92s\n",
            "665:\tlearn: 39404.0816186\ttotal: 9.77s\tremaining: 4.9s\n",
            "666:\tlearn: 39395.6078934\ttotal: 9.79s\tremaining: 4.89s\n",
            "667:\tlearn: 39382.9661623\ttotal: 9.8s\tremaining: 4.87s\n",
            "668:\tlearn: 39375.4366106\ttotal: 9.82s\tremaining: 4.86s\n",
            "669:\tlearn: 39354.8856874\ttotal: 9.83s\tremaining: 4.84s\n",
            "670:\tlearn: 39322.3917220\ttotal: 9.84s\tremaining: 4.83s\n",
            "671:\tlearn: 39309.0104557\ttotal: 9.86s\tremaining: 4.81s\n",
            "672:\tlearn: 39291.4046616\ttotal: 9.88s\tremaining: 4.8s\n",
            "673:\tlearn: 39275.7761851\ttotal: 9.9s\tremaining: 4.79s\n",
            "674:\tlearn: 39258.9973959\ttotal: 9.91s\tremaining: 4.77s\n",
            "675:\tlearn: 39247.0110862\ttotal: 9.93s\tremaining: 4.76s\n",
            "676:\tlearn: 39234.8384145\ttotal: 9.94s\tremaining: 4.74s\n",
            "677:\tlearn: 39227.3941406\ttotal: 9.96s\tremaining: 4.73s\n",
            "678:\tlearn: 39215.2171529\ttotal: 9.97s\tremaining: 4.71s\n",
            "679:\tlearn: 39207.1084294\ttotal: 9.98s\tremaining: 4.7s\n",
            "680:\tlearn: 39196.2972543\ttotal: 10s\tremaining: 4.68s\n",
            "681:\tlearn: 39189.5130716\ttotal: 10s\tremaining: 4.67s\n",
            "682:\tlearn: 39177.0177778\ttotal: 10s\tremaining: 4.65s\n",
            "683:\tlearn: 39171.8335268\ttotal: 10s\tremaining: 4.64s\n",
            "684:\tlearn: 39161.9468772\ttotal: 10.1s\tremaining: 4.62s\n",
            "685:\tlearn: 39146.8527284\ttotal: 10.1s\tremaining: 4.61s\n",
            "686:\tlearn: 39139.4068719\ttotal: 10.1s\tremaining: 4.59s\n",
            "687:\tlearn: 39123.2058565\ttotal: 10.1s\tremaining: 4.58s\n",
            "688:\tlearn: 39117.5745013\ttotal: 10.1s\tremaining: 4.57s\n",
            "689:\tlearn: 39107.6854730\ttotal: 10.1s\tremaining: 4.55s\n",
            "690:\tlearn: 39091.5632316\ttotal: 10.1s\tremaining: 4.54s\n",
            "691:\tlearn: 39076.8869892\ttotal: 10.2s\tremaining: 4.52s\n",
            "692:\tlearn: 39066.8634776\ttotal: 10.2s\tremaining: 4.51s\n",
            "693:\tlearn: 39052.8254043\ttotal: 10.2s\tremaining: 4.49s\n",
            "694:\tlearn: 39042.4214244\ttotal: 10.2s\tremaining: 4.48s\n",
            "695:\tlearn: 39028.6893815\ttotal: 10.2s\tremaining: 4.46s\n",
            "696:\tlearn: 39018.2769652\ttotal: 10.2s\tremaining: 4.45s\n",
            "697:\tlearn: 39011.6422181\ttotal: 10.2s\tremaining: 4.43s\n",
            "698:\tlearn: 38998.4807624\ttotal: 10.3s\tremaining: 4.42s\n",
            "699:\tlearn: 38977.0604492\ttotal: 10.3s\tremaining: 4.4s\n",
            "700:\tlearn: 38961.0734341\ttotal: 10.3s\tremaining: 4.39s\n",
            "701:\tlearn: 38957.2425506\ttotal: 10.3s\tremaining: 4.38s\n",
            "702:\tlearn: 38943.9571108\ttotal: 10.3s\tremaining: 4.36s\n",
            "703:\tlearn: 38933.9318141\ttotal: 10.3s\tremaining: 4.35s\n",
            "704:\tlearn: 38923.2543350\ttotal: 10.4s\tremaining: 4.33s\n",
            "705:\tlearn: 38905.1100527\ttotal: 10.4s\tremaining: 4.32s\n",
            "706:\tlearn: 38893.3436260\ttotal: 10.4s\tremaining: 4.3s\n",
            "707:\tlearn: 38889.0723846\ttotal: 10.4s\tremaining: 4.29s\n",
            "708:\tlearn: 38880.2813528\ttotal: 10.4s\tremaining: 4.27s\n",
            "709:\tlearn: 38852.7575457\ttotal: 10.4s\tremaining: 4.26s\n",
            "710:\tlearn: 38833.8989273\ttotal: 10.4s\tremaining: 4.24s\n",
            "711:\tlearn: 38824.4615887\ttotal: 10.4s\tremaining: 4.23s\n",
            "712:\tlearn: 38798.0380845\ttotal: 10.5s\tremaining: 4.21s\n",
            "713:\tlearn: 38784.7465657\ttotal: 10.5s\tremaining: 4.2s\n",
            "714:\tlearn: 38769.3505163\ttotal: 10.5s\tremaining: 4.18s\n",
            "715:\tlearn: 38760.0904120\ttotal: 10.5s\tremaining: 4.17s\n",
            "716:\tlearn: 38751.5323130\ttotal: 10.5s\tremaining: 4.16s\n",
            "717:\tlearn: 38735.3061828\ttotal: 10.5s\tremaining: 4.14s\n",
            "718:\tlearn: 38723.4900015\ttotal: 10.6s\tremaining: 4.13s\n",
            "719:\tlearn: 38712.1287912\ttotal: 10.6s\tremaining: 4.11s\n",
            "720:\tlearn: 38703.6919231\ttotal: 10.6s\tremaining: 4.11s\n",
            "721:\tlearn: 38692.8104058\ttotal: 10.6s\tremaining: 4.09s\n",
            "722:\tlearn: 38684.8802447\ttotal: 10.6s\tremaining: 4.08s\n",
            "723:\tlearn: 38677.2140552\ttotal: 10.7s\tremaining: 4.06s\n",
            "724:\tlearn: 38650.3861911\ttotal: 10.7s\tremaining: 4.05s\n",
            "725:\tlearn: 38639.2657086\ttotal: 10.7s\tremaining: 4.03s\n",
            "726:\tlearn: 38622.8624917\ttotal: 10.7s\tremaining: 4.02s\n",
            "727:\tlearn: 38615.1746132\ttotal: 10.7s\tremaining: 4s\n",
            "728:\tlearn: 38606.4095593\ttotal: 10.7s\tremaining: 3.99s\n",
            "729:\tlearn: 38590.8848586\ttotal: 10.7s\tremaining: 3.97s\n",
            "730:\tlearn: 38582.8668316\ttotal: 10.8s\tremaining: 3.96s\n",
            "731:\tlearn: 38571.6216788\ttotal: 10.8s\tremaining: 3.94s\n",
            "732:\tlearn: 38564.4954314\ttotal: 10.8s\tremaining: 3.93s\n",
            "733:\tlearn: 38557.1756669\ttotal: 10.8s\tremaining: 3.91s\n",
            "734:\tlearn: 38543.9915922\ttotal: 10.8s\tremaining: 3.9s\n",
            "735:\tlearn: 38530.1566516\ttotal: 10.8s\tremaining: 3.88s\n",
            "736:\tlearn: 38497.7936005\ttotal: 10.8s\tremaining: 3.87s\n",
            "737:\tlearn: 38491.8030893\ttotal: 10.9s\tremaining: 3.85s\n",
            "738:\tlearn: 38462.5192861\ttotal: 10.9s\tremaining: 3.84s\n",
            "739:\tlearn: 38448.9591583\ttotal: 10.9s\tremaining: 3.82s\n",
            "740:\tlearn: 38434.3894346\ttotal: 10.9s\tremaining: 3.81s\n",
            "741:\tlearn: 38426.6364279\ttotal: 10.9s\tremaining: 3.79s\n",
            "742:\tlearn: 38413.6820839\ttotal: 10.9s\tremaining: 3.78s\n",
            "743:\tlearn: 38406.9863318\ttotal: 10.9s\tremaining: 3.77s\n",
            "744:\tlearn: 38395.7163119\ttotal: 11s\tremaining: 3.75s\n",
            "745:\tlearn: 38386.3007615\ttotal: 11s\tremaining: 3.74s\n",
            "746:\tlearn: 38372.5247789\ttotal: 11s\tremaining: 3.72s\n",
            "747:\tlearn: 38352.5579963\ttotal: 11s\tremaining: 3.71s\n",
            "748:\tlearn: 38343.5957751\ttotal: 11s\tremaining: 3.69s\n",
            "749:\tlearn: 38330.5200393\ttotal: 11s\tremaining: 3.68s\n",
            "750:\tlearn: 38323.5481023\ttotal: 11s\tremaining: 3.66s\n",
            "751:\tlearn: 38316.2806501\ttotal: 11.1s\tremaining: 3.65s\n",
            "752:\tlearn: 38311.0939088\ttotal: 11.1s\tremaining: 3.63s\n",
            "753:\tlearn: 38298.0329920\ttotal: 11.1s\tremaining: 3.62s\n",
            "754:\tlearn: 38287.4145891\ttotal: 11.1s\tremaining: 3.6s\n",
            "755:\tlearn: 38280.5561091\ttotal: 11.1s\tremaining: 3.59s\n",
            "756:\tlearn: 38261.7884721\ttotal: 11.1s\tremaining: 3.57s\n",
            "757:\tlearn: 38250.3206470\ttotal: 11.2s\tremaining: 3.56s\n",
            "758:\tlearn: 38243.9304207\ttotal: 11.2s\tremaining: 3.55s\n",
            "759:\tlearn: 38239.7197930\ttotal: 11.2s\tremaining: 3.53s\n",
            "760:\tlearn: 38228.5659653\ttotal: 11.2s\tremaining: 3.52s\n",
            "761:\tlearn: 38221.9607243\ttotal: 11.2s\tremaining: 3.5s\n",
            "762:\tlearn: 38216.1573553\ttotal: 11.2s\tremaining: 3.48s\n",
            "763:\tlearn: 38200.4022568\ttotal: 11.2s\tremaining: 3.47s\n",
            "764:\tlearn: 38191.2405502\ttotal: 11.3s\tremaining: 3.46s\n",
            "765:\tlearn: 38182.6658528\ttotal: 11.3s\tremaining: 3.44s\n",
            "766:\tlearn: 38165.1793927\ttotal: 11.3s\tremaining: 3.43s\n",
            "767:\tlearn: 38154.4195986\ttotal: 11.3s\tremaining: 3.41s\n",
            "768:\tlearn: 38142.9340988\ttotal: 11.3s\tremaining: 3.4s\n",
            "769:\tlearn: 38129.0810936\ttotal: 11.3s\tremaining: 3.38s\n",
            "770:\tlearn: 38098.3757599\ttotal: 11.3s\tremaining: 3.37s\n",
            "771:\tlearn: 38092.7915521\ttotal: 11.4s\tremaining: 3.36s\n",
            "772:\tlearn: 38084.1610639\ttotal: 11.4s\tremaining: 3.34s\n",
            "773:\tlearn: 38074.4269640\ttotal: 11.4s\tremaining: 3.33s\n",
            "774:\tlearn: 38066.8626587\ttotal: 11.4s\tremaining: 3.31s\n",
            "775:\tlearn: 38048.9682210\ttotal: 11.4s\tremaining: 3.3s\n",
            "776:\tlearn: 38037.7209296\ttotal: 11.4s\tremaining: 3.28s\n",
            "777:\tlearn: 38014.2413509\ttotal: 11.4s\tremaining: 3.27s\n",
            "778:\tlearn: 38008.3115848\ttotal: 11.5s\tremaining: 3.25s\n",
            "779:\tlearn: 37993.6662305\ttotal: 11.5s\tremaining: 3.24s\n",
            "780:\tlearn: 37990.0681954\ttotal: 11.5s\tremaining: 3.22s\n",
            "781:\tlearn: 37978.5224896\ttotal: 11.5s\tremaining: 3.21s\n",
            "782:\tlearn: 37972.0084510\ttotal: 11.5s\tremaining: 3.19s\n",
            "783:\tlearn: 37968.6634885\ttotal: 11.5s\tremaining: 3.18s\n",
            "784:\tlearn: 37951.1153049\ttotal: 11.5s\tremaining: 3.16s\n",
            "785:\tlearn: 37944.2528471\ttotal: 11.6s\tremaining: 3.15s\n",
            "786:\tlearn: 37934.2625817\ttotal: 11.6s\tremaining: 3.13s\n",
            "787:\tlearn: 37929.3573961\ttotal: 11.6s\tremaining: 3.12s\n",
            "788:\tlearn: 37909.8386780\ttotal: 11.6s\tremaining: 3.1s\n",
            "789:\tlearn: 37898.2830019\ttotal: 11.6s\tremaining: 3.09s\n",
            "790:\tlearn: 37889.4023143\ttotal: 11.6s\tremaining: 3.07s\n",
            "791:\tlearn: 37879.3367704\ttotal: 11.7s\tremaining: 3.06s\n",
            "792:\tlearn: 37873.3577394\ttotal: 11.7s\tremaining: 3.04s\n",
            "793:\tlearn: 37868.3463577\ttotal: 11.7s\tremaining: 3.03s\n",
            "794:\tlearn: 37854.1264266\ttotal: 11.7s\tremaining: 3.01s\n",
            "795:\tlearn: 37844.5389311\ttotal: 11.7s\tremaining: 3s\n",
            "796:\tlearn: 37832.0454717\ttotal: 11.7s\tremaining: 2.98s\n",
            "797:\tlearn: 37823.4900165\ttotal: 11.7s\tremaining: 2.97s\n",
            "798:\tlearn: 37789.5814903\ttotal: 11.8s\tremaining: 2.96s\n",
            "799:\tlearn: 37775.6460490\ttotal: 11.8s\tremaining: 2.94s\n",
            "800:\tlearn: 37768.6445730\ttotal: 11.8s\tremaining: 2.93s\n",
            "801:\tlearn: 37759.1064434\ttotal: 11.8s\tremaining: 2.91s\n",
            "802:\tlearn: 37752.4409560\ttotal: 11.8s\tremaining: 2.9s\n",
            "803:\tlearn: 37734.7215448\ttotal: 11.8s\tremaining: 2.88s\n",
            "804:\tlearn: 37726.4810035\ttotal: 11.8s\tremaining: 2.87s\n",
            "805:\tlearn: 37716.7152585\ttotal: 11.9s\tremaining: 2.85s\n",
            "806:\tlearn: 37712.0653455\ttotal: 11.9s\tremaining: 2.84s\n",
            "807:\tlearn: 37698.2371728\ttotal: 11.9s\tremaining: 2.82s\n",
            "808:\tlearn: 37687.6021782\ttotal: 11.9s\tremaining: 2.81s\n",
            "809:\tlearn: 37681.6125239\ttotal: 11.9s\tremaining: 2.79s\n",
            "810:\tlearn: 37677.4757485\ttotal: 11.9s\tremaining: 2.78s\n",
            "811:\tlearn: 37673.5133164\ttotal: 11.9s\tremaining: 2.77s\n",
            "812:\tlearn: 37659.5555422\ttotal: 12s\tremaining: 2.75s\n",
            "813:\tlearn: 37652.5150567\ttotal: 12s\tremaining: 2.74s\n",
            "814:\tlearn: 37642.4295538\ttotal: 12s\tremaining: 2.72s\n",
            "815:\tlearn: 37626.6927913\ttotal: 12s\tremaining: 2.71s\n",
            "816:\tlearn: 37621.4895899\ttotal: 12s\tremaining: 2.69s\n",
            "817:\tlearn: 37604.0956292\ttotal: 12s\tremaining: 2.68s\n",
            "818:\tlearn: 37594.1240783\ttotal: 12.1s\tremaining: 2.66s\n",
            "819:\tlearn: 37569.6822479\ttotal: 12.1s\tremaining: 2.65s\n",
            "820:\tlearn: 37555.6383668\ttotal: 12.1s\tremaining: 2.63s\n",
            "821:\tlearn: 37550.5819918\ttotal: 12.1s\tremaining: 2.62s\n",
            "822:\tlearn: 37545.8647137\ttotal: 12.1s\tremaining: 2.6s\n",
            "823:\tlearn: 37528.1006582\ttotal: 12.1s\tremaining: 2.59s\n",
            "824:\tlearn: 37522.7718005\ttotal: 12.1s\tremaining: 2.58s\n",
            "825:\tlearn: 37515.5244043\ttotal: 12.2s\tremaining: 2.56s\n",
            "826:\tlearn: 37504.7379259\ttotal: 12.2s\tremaining: 2.55s\n",
            "827:\tlearn: 37467.9733721\ttotal: 12.2s\tremaining: 2.53s\n",
            "828:\tlearn: 37459.8286881\ttotal: 12.2s\tremaining: 2.52s\n",
            "829:\tlearn: 37446.8365833\ttotal: 12.2s\tremaining: 2.5s\n",
            "830:\tlearn: 37436.4234636\ttotal: 12.2s\tremaining: 2.49s\n",
            "831:\tlearn: 37429.8403077\ttotal: 12.2s\tremaining: 2.47s\n",
            "832:\tlearn: 37418.5815807\ttotal: 12.3s\tremaining: 2.46s\n",
            "833:\tlearn: 37413.3905211\ttotal: 12.3s\tremaining: 2.44s\n",
            "834:\tlearn: 37404.5869798\ttotal: 12.3s\tremaining: 2.43s\n",
            "835:\tlearn: 37395.1862258\ttotal: 12.3s\tremaining: 2.41s\n",
            "836:\tlearn: 37384.5803733\ttotal: 12.3s\tremaining: 2.4s\n",
            "837:\tlearn: 37366.8759046\ttotal: 12.3s\tremaining: 2.38s\n",
            "838:\tlearn: 37357.4854263\ttotal: 12.3s\tremaining: 2.37s\n",
            "839:\tlearn: 37350.2556688\ttotal: 12.4s\tremaining: 2.35s\n",
            "840:\tlearn: 37342.9144916\ttotal: 12.4s\tremaining: 2.34s\n",
            "841:\tlearn: 37333.1036882\ttotal: 12.4s\tremaining: 2.33s\n",
            "842:\tlearn: 37324.6942260\ttotal: 12.4s\tremaining: 2.31s\n",
            "843:\tlearn: 37312.7858748\ttotal: 12.4s\tremaining: 2.3s\n",
            "844:\tlearn: 37279.3530170\ttotal: 12.4s\tremaining: 2.28s\n",
            "845:\tlearn: 37271.4532420\ttotal: 12.5s\tremaining: 2.27s\n",
            "846:\tlearn: 37263.2200833\ttotal: 12.5s\tremaining: 2.25s\n",
            "847:\tlearn: 37256.3579539\ttotal: 12.5s\tremaining: 2.24s\n",
            "848:\tlearn: 37246.4145416\ttotal: 12.5s\tremaining: 2.22s\n",
            "849:\tlearn: 37233.7603824\ttotal: 12.5s\tremaining: 2.21s\n",
            "850:\tlearn: 37225.5388311\ttotal: 12.5s\tremaining: 2.19s\n",
            "851:\tlearn: 37218.6650269\ttotal: 12.5s\tremaining: 2.18s\n",
            "852:\tlearn: 37211.1155709\ttotal: 12.6s\tremaining: 2.16s\n",
            "853:\tlearn: 37202.0432326\ttotal: 12.6s\tremaining: 2.15s\n",
            "854:\tlearn: 37192.6210898\ttotal: 12.6s\tremaining: 2.13s\n",
            "855:\tlearn: 37182.9952360\ttotal: 12.6s\tremaining: 2.12s\n",
            "856:\tlearn: 37176.7319539\ttotal: 12.6s\tremaining: 2.1s\n",
            "857:\tlearn: 37159.3973974\ttotal: 12.6s\tremaining: 2.09s\n",
            "858:\tlearn: 37154.3571086\ttotal: 12.6s\tremaining: 2.08s\n",
            "859:\tlearn: 37126.9428908\ttotal: 12.7s\tremaining: 2.06s\n",
            "860:\tlearn: 37114.0427792\ttotal: 12.7s\tremaining: 2.05s\n",
            "861:\tlearn: 37104.4897049\ttotal: 12.7s\tremaining: 2.03s\n",
            "862:\tlearn: 37090.8102301\ttotal: 12.7s\tremaining: 2.02s\n",
            "863:\tlearn: 37079.3639900\ttotal: 12.7s\tremaining: 2s\n",
            "864:\tlearn: 37066.9360441\ttotal: 12.7s\tremaining: 1.99s\n",
            "865:\tlearn: 37054.9115173\ttotal: 12.7s\tremaining: 1.97s\n",
            "866:\tlearn: 37048.7616567\ttotal: 12.8s\tremaining: 1.96s\n",
            "867:\tlearn: 37037.3617702\ttotal: 12.8s\tremaining: 1.94s\n",
            "868:\tlearn: 37011.5249429\ttotal: 12.8s\tremaining: 1.93s\n",
            "869:\tlearn: 36986.8396727\ttotal: 12.8s\tremaining: 1.91s\n",
            "870:\tlearn: 36976.0033332\ttotal: 12.8s\tremaining: 1.9s\n",
            "871:\tlearn: 36948.0173642\ttotal: 12.8s\tremaining: 1.89s\n",
            "872:\tlearn: 36935.4044559\ttotal: 12.9s\tremaining: 1.87s\n",
            "873:\tlearn: 36916.1290120\ttotal: 12.9s\tremaining: 1.85s\n",
            "874:\tlearn: 36908.8842600\ttotal: 12.9s\tremaining: 1.84s\n",
            "875:\tlearn: 36883.5534175\ttotal: 12.9s\tremaining: 1.83s\n",
            "876:\tlearn: 36878.7531074\ttotal: 12.9s\tremaining: 1.81s\n",
            "877:\tlearn: 36870.4117179\ttotal: 12.9s\tremaining: 1.8s\n",
            "878:\tlearn: 36863.7170230\ttotal: 12.9s\tremaining: 1.78s\n",
            "879:\tlearn: 36854.6997209\ttotal: 13s\tremaining: 1.77s\n",
            "880:\tlearn: 36842.2874516\ttotal: 13s\tremaining: 1.75s\n",
            "881:\tlearn: 36835.4526753\ttotal: 13s\tremaining: 1.74s\n",
            "882:\tlearn: 36831.8371443\ttotal: 13s\tremaining: 1.72s\n",
            "883:\tlearn: 36826.1929336\ttotal: 13s\tremaining: 1.71s\n",
            "884:\tlearn: 36816.4243922\ttotal: 13s\tremaining: 1.69s\n",
            "885:\tlearn: 36809.6233587\ttotal: 13.1s\tremaining: 1.68s\n",
            "886:\tlearn: 36795.9639809\ttotal: 13.1s\tremaining: 1.66s\n",
            "887:\tlearn: 36785.6580267\ttotal: 13.1s\tremaining: 1.65s\n",
            "888:\tlearn: 36772.3846766\ttotal: 13.1s\tremaining: 1.63s\n",
            "889:\tlearn: 36751.7446959\ttotal: 13.1s\tremaining: 1.62s\n",
            "890:\tlearn: 36740.6873372\ttotal: 13.1s\tremaining: 1.6s\n",
            "891:\tlearn: 36730.2293259\ttotal: 13.1s\tremaining: 1.59s\n",
            "892:\tlearn: 36720.1742185\ttotal: 13.1s\tremaining: 1.57s\n",
            "893:\tlearn: 36710.5084527\ttotal: 13.2s\tremaining: 1.56s\n",
            "894:\tlearn: 36701.2281393\ttotal: 13.2s\tremaining: 1.55s\n",
            "895:\tlearn: 36688.4247600\ttotal: 13.2s\tremaining: 1.53s\n",
            "896:\tlearn: 36679.7644307\ttotal: 13.2s\tremaining: 1.52s\n",
            "897:\tlearn: 36674.7190629\ttotal: 13.2s\tremaining: 1.5s\n",
            "898:\tlearn: 36656.5562576\ttotal: 13.3s\tremaining: 1.49s\n",
            "899:\tlearn: 36641.8837554\ttotal: 13.3s\tremaining: 1.47s\n",
            "900:\tlearn: 36631.9081783\ttotal: 13.3s\tremaining: 1.46s\n",
            "901:\tlearn: 36624.6246150\ttotal: 13.3s\tremaining: 1.44s\n",
            "902:\tlearn: 36599.4269955\ttotal: 13.3s\tremaining: 1.43s\n",
            "903:\tlearn: 36593.0791622\ttotal: 13.3s\tremaining: 1.42s\n",
            "904:\tlearn: 36585.0706514\ttotal: 13.3s\tremaining: 1.4s\n",
            "905:\tlearn: 36574.1629085\ttotal: 13.4s\tremaining: 1.39s\n",
            "906:\tlearn: 36567.7948126\ttotal: 13.4s\tremaining: 1.37s\n",
            "907:\tlearn: 36551.4623015\ttotal: 13.4s\tremaining: 1.35s\n",
            "908:\tlearn: 36538.9635481\ttotal: 13.4s\tremaining: 1.34s\n",
            "909:\tlearn: 36512.9968072\ttotal: 13.4s\tremaining: 1.33s\n",
            "910:\tlearn: 36498.4897824\ttotal: 13.4s\tremaining: 1.31s\n",
            "911:\tlearn: 36489.3908574\ttotal: 13.4s\tremaining: 1.3s\n",
            "912:\tlearn: 36476.1064549\ttotal: 13.4s\tremaining: 1.28s\n",
            "913:\tlearn: 36464.5164767\ttotal: 13.5s\tremaining: 1.27s\n",
            "914:\tlearn: 36461.9356061\ttotal: 13.5s\tremaining: 1.25s\n",
            "915:\tlearn: 36452.1982629\ttotal: 13.5s\tremaining: 1.24s\n",
            "916:\tlearn: 36448.0931101\ttotal: 13.5s\tremaining: 1.22s\n",
            "917:\tlearn: 36441.9125755\ttotal: 13.5s\tremaining: 1.21s\n",
            "918:\tlearn: 36429.2226955\ttotal: 13.5s\tremaining: 1.19s\n",
            "919:\tlearn: 36421.7030473\ttotal: 13.6s\tremaining: 1.18s\n",
            "920:\tlearn: 36400.2049094\ttotal: 13.6s\tremaining: 1.16s\n",
            "921:\tlearn: 36390.2849742\ttotal: 13.6s\tremaining: 1.15s\n",
            "922:\tlearn: 36376.3925313\ttotal: 13.6s\tremaining: 1.13s\n",
            "923:\tlearn: 36372.1687093\ttotal: 13.6s\tremaining: 1.12s\n",
            "924:\tlearn: 36366.9376872\ttotal: 13.6s\tremaining: 1.1s\n",
            "925:\tlearn: 36358.9318777\ttotal: 13.6s\tremaining: 1.09s\n",
            "926:\tlearn: 36350.8359949\ttotal: 13.7s\tremaining: 1.07s\n",
            "927:\tlearn: 36331.0826839\ttotal: 13.7s\tremaining: 1.06s\n",
            "928:\tlearn: 36325.2791545\ttotal: 13.7s\tremaining: 1.05s\n",
            "929:\tlearn: 36321.3291372\ttotal: 13.7s\tremaining: 1.03s\n",
            "930:\tlearn: 36309.1777099\ttotal: 13.7s\tremaining: 1.02s\n",
            "931:\tlearn: 36299.8359929\ttotal: 13.7s\tremaining: 1s\n",
            "932:\tlearn: 36296.1329823\ttotal: 13.7s\tremaining: 987ms\n",
            "933:\tlearn: 36290.4122860\ttotal: 13.8s\tremaining: 972ms\n",
            "934:\tlearn: 36277.4492401\ttotal: 13.8s\tremaining: 958ms\n",
            "935:\tlearn: 36270.8260215\ttotal: 13.8s\tremaining: 943ms\n",
            "936:\tlearn: 36247.5282809\ttotal: 13.8s\tremaining: 928ms\n",
            "937:\tlearn: 36239.0077649\ttotal: 13.8s\tremaining: 913ms\n",
            "938:\tlearn: 36225.6711506\ttotal: 13.8s\tremaining: 898ms\n",
            "939:\tlearn: 36210.2911668\ttotal: 13.8s\tremaining: 884ms\n",
            "940:\tlearn: 36204.8099883\ttotal: 13.9s\tremaining: 869ms\n",
            "941:\tlearn: 36195.7587986\ttotal: 13.9s\tremaining: 855ms\n",
            "942:\tlearn: 36188.1555944\ttotal: 13.9s\tremaining: 840ms\n",
            "943:\tlearn: 36172.0349699\ttotal: 13.9s\tremaining: 825ms\n",
            "944:\tlearn: 36164.4985309\ttotal: 13.9s\tremaining: 810ms\n",
            "945:\tlearn: 36155.2609249\ttotal: 13.9s\tremaining: 795ms\n",
            "946:\tlearn: 36144.0533579\ttotal: 13.9s\tremaining: 781ms\n",
            "947:\tlearn: 36137.0478398\ttotal: 14s\tremaining: 766ms\n",
            "948:\tlearn: 36131.5010742\ttotal: 14s\tremaining: 751ms\n",
            "949:\tlearn: 36124.7745282\ttotal: 14s\tremaining: 736ms\n",
            "950:\tlearn: 36114.7292866\ttotal: 14s\tremaining: 721ms\n",
            "951:\tlearn: 36102.8797359\ttotal: 14s\tremaining: 707ms\n",
            "952:\tlearn: 36098.1378786\ttotal: 14s\tremaining: 692ms\n",
            "953:\tlearn: 36088.6753248\ttotal: 14s\tremaining: 677ms\n",
            "954:\tlearn: 36081.7925836\ttotal: 14.1s\tremaining: 662ms\n",
            "955:\tlearn: 36061.8935400\ttotal: 14.1s\tremaining: 648ms\n",
            "956:\tlearn: 36048.3579125\ttotal: 14.1s\tremaining: 633ms\n",
            "957:\tlearn: 36038.4451660\ttotal: 14.1s\tremaining: 619ms\n",
            "958:\tlearn: 36032.3989795\ttotal: 14.1s\tremaining: 604ms\n",
            "959:\tlearn: 36026.0942833\ttotal: 14.1s\tremaining: 589ms\n",
            "960:\tlearn: 35999.2975519\ttotal: 14.2s\tremaining: 574ms\n",
            "961:\tlearn: 35976.6306572\ttotal: 14.2s\tremaining: 560ms\n",
            "962:\tlearn: 35964.7265446\ttotal: 14.2s\tremaining: 545ms\n",
            "963:\tlearn: 35957.6454782\ttotal: 14.2s\tremaining: 530ms\n",
            "964:\tlearn: 35946.6280766\ttotal: 14.2s\tremaining: 515ms\n",
            "965:\tlearn: 35937.3160645\ttotal: 14.2s\tremaining: 501ms\n",
            "966:\tlearn: 35926.1749881\ttotal: 14.2s\tremaining: 486ms\n",
            "967:\tlearn: 35919.1396690\ttotal: 14.2s\tremaining: 471ms\n",
            "968:\tlearn: 35912.4025481\ttotal: 14.3s\tremaining: 456ms\n",
            "969:\tlearn: 35900.7829490\ttotal: 14.3s\tremaining: 442ms\n",
            "970:\tlearn: 35895.8773758\ttotal: 14.3s\tremaining: 427ms\n",
            "971:\tlearn: 35884.8738411\ttotal: 14.3s\tremaining: 412ms\n",
            "972:\tlearn: 35876.6127547\ttotal: 14.3s\tremaining: 398ms\n",
            "973:\tlearn: 35865.2877665\ttotal: 14.3s\tremaining: 383ms\n",
            "974:\tlearn: 35859.4981275\ttotal: 14.4s\tremaining: 368ms\n",
            "975:\tlearn: 35846.8977341\ttotal: 14.4s\tremaining: 353ms\n",
            "976:\tlearn: 35841.0070408\ttotal: 14.4s\tremaining: 339ms\n",
            "977:\tlearn: 35835.1537803\ttotal: 14.4s\tremaining: 324ms\n",
            "978:\tlearn: 35826.6608792\ttotal: 14.4s\tremaining: 309ms\n",
            "979:\tlearn: 35812.5211395\ttotal: 14.4s\tremaining: 294ms\n",
            "980:\tlearn: 35797.2629614\ttotal: 14.4s\tremaining: 280ms\n",
            "981:\tlearn: 35791.1739438\ttotal: 14.5s\tremaining: 265ms\n",
            "982:\tlearn: 35783.5890083\ttotal: 14.5s\tremaining: 250ms\n",
            "983:\tlearn: 35778.1331153\ttotal: 14.5s\tremaining: 235ms\n",
            "984:\tlearn: 35770.2739796\ttotal: 14.5s\tremaining: 221ms\n",
            "985:\tlearn: 35755.4923872\ttotal: 14.5s\tremaining: 206ms\n",
            "986:\tlearn: 35741.5089830\ttotal: 14.5s\tremaining: 191ms\n",
            "987:\tlearn: 35733.5893058\ttotal: 14.5s\tremaining: 177ms\n",
            "988:\tlearn: 35721.5177858\ttotal: 14.6s\tremaining: 162ms\n",
            "989:\tlearn: 35712.7983261\ttotal: 14.6s\tremaining: 147ms\n",
            "990:\tlearn: 35704.4388332\ttotal: 14.6s\tremaining: 133ms\n",
            "991:\tlearn: 35698.1824968\ttotal: 14.6s\tremaining: 118ms\n",
            "992:\tlearn: 35684.7758719\ttotal: 14.6s\tremaining: 103ms\n",
            "993:\tlearn: 35667.1214056\ttotal: 14.6s\tremaining: 88.4ms\n",
            "994:\tlearn: 35635.2769349\ttotal: 14.7s\tremaining: 73.6ms\n",
            "995:\tlearn: 35626.3033409\ttotal: 14.7s\tremaining: 58.9ms\n",
            "996:\tlearn: 35618.2867293\ttotal: 14.7s\tremaining: 44.2ms\n",
            "997:\tlearn: 35613.8913389\ttotal: 14.7s\tremaining: 29.4ms\n",
            "998:\tlearn: 35599.9892017\ttotal: 14.7s\tremaining: 14.7ms\n",
            "999:\tlearn: 35592.1197447\ttotal: 14.7s\tremaining: 0us\n",
            "The accuracy of the CAT Regression is 0.8281214032409422\n",
            "60911.80106837194\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vd_tzWYFVrYP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Lets do prediction on testing data. We need to scale test data as well\n",
        "# We did prediction on other algorithms and I have commented as finally i have used RandomForest regression model\n",
        "\n",
        "#test_X_ts = scaler.transform(test_col)\n",
        "\n",
        "#pred0 = xgb.predict(test_X_ts)\n",
        "#pred1 = clf.predict(test_X_ts)\n",
        "#pred2 = cb.predict(test_X_ts)\n",
        "#pred3 = lb.predict(test_X_ts)\n",
        "#actual_predictions = (pred0+pred1+pred2+pred3)/4\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmNYbH5ZOnj9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Lets predict Income variable for test data using Random Forest Regression\n",
        "\n",
        "test_X_ts = scaler.transform(test_col)\n",
        "predictions = cls.predict(test_X_ts)\n",
        "\n",
        "\n",
        "#  Below predcitions were used when we take log of Income variable but it didn't help RMSE on public board, hence i got rid of below method.\n",
        "\n",
        "#pred = cls.predict(test_col)\n",
        "#predictions = np.exp(pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ce4DgHf2VrYR",
        "colab_type": "code",
        "outputId": "6587c728-c875-4b1b-a2f7-76907ab6f9e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "predictions.max()"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3651249.457859998"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_e4vibSdVrYT",
        "colab_type": "code",
        "outputId": "f3970f27-e949-43a2-c67d-d872e8e1385f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#lets submit our predictions on test data\n",
        "\n",
        "\n",
        "submissions =pd.DataFrame({'Instance': test_df['Instance'], 'Income': predictions}, columns =['Instance','Income'])\n",
        "filename ='tcd ml 2019-20 income prediction submission file.csv'\n",
        "submissions.to_csv(filename, index=False)\n",
        "print('Saved File '+ filename)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved File tcd ml 2019-20 income prediction submission file.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "865Qgsf8Z4Gv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# In conclusion, many regression techniques gave me better RMSE on validation data and other boosting algorithm gave me boost to RMSE; however model got overfitted on testing data and brought my RMSE down."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmwWQ7i1b-DA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}